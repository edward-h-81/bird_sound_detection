{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"custom_dataset_dcase.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPFi9z5jb0XSEhiwhdPjEU/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"NcK7L1OA1Tgu"},"source":["# Load the Drive helper and mount\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gsefAZfHCDud"},"source":["!pip install torchaudio"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1chFvuLA4EqQ","executionInfo":{"status":"ok","timestamp":1628186569619,"user_tz":-60,"elapsed":204,"user":{"displayName":"Edward Hulme","photoUrl":"","userId":"12267249823946796482"}},"outputId":"a6f99204-0e13-4343-e89a-6882f0602139"},"source":["from torch.utils.data import Dataset\n","import pandas as pd\n","import torchaudio\n","import os\n","import torch\n","\n","class DCASE_Dataset(Dataset):\n","\n","  def __init__(self, annotations_file, audio_dir, transformation,\n","               target_sample_rate):\n","    self.annotations = pd.read_csv(annotations_file)\n","    self.audio_dir = audio_dir\n","    self.transformation = transformation\n","    self.target_sample_rate = target_sample_rate\n","\n","  def __len__(self):\n","    return len(self.annotations)\n","\n","  def __getitem__(self, index):\n","    audio_sample_path = self._get_audio_sample_path(index)\n","    label = self._get_audio_sample_label(index)\n","    filename = self._get_audio_sample_filename(index)\n","    signal, sr = torchaudio.load(audio_sample_path) \n","    signal = self._resample_if_necessary(signal, sr)\n","    signal = self._mix_down_if_necessary(signal)\n","    signal = self.transformation(signal) \n","    return signal, label, filename\n","\n","  def _resample_if_necessary(self, signal, sr):\n","    if sr != self.target_sample_rate:\n","        resampler = torchaudio.transforms.Resample(sr, self.target_sample_rate)\n","        signal = resampler(signal)\n","    return signal\n","\n","  def _mix_down_if_necessary(self, signal):\n","    if signal.shape[0] > 1: \n","        signal = torch.mean(signal, dim=0, keepdim=True)\n","    return signal\n","\n","  def _get_audio_sample_path(self, index):\n","    fold = f\"{self.annotations.iloc[index, 1]}\"\n","    path = os.path.join(self.audio_dir, fold, f\"{self.annotations.iloc[index, 0]}.wav\")\n","    return path\n","\n","  def _get_audio_sample_label(self, index):\n","    return self.annotations.iloc[index, 2]\n","\n","  def _get_audio_sample_filename(self, index):\n","    return f\"{self.annotations.iloc[index, 0]}.wav\"\n","\n","if __name__ == \"__main__\":\n","\n","  ANNOTATIONS_FILE = '/content/drive/My Drive/DCASE_Datasets/labels/combined_metadata.csv'\n","  AUDIO_DIR = '/content/drive/My Drive/DCASE_Datasets/audio/'\n","  SAMPLE_RATE = 22050\n","\n","  mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n","      sample_rate=SAMPLE_RATE,\n","      n_fft=1024,\n","      hop_length=512,\n","      n_mels=64\n","      )\n","\n","  dcase_data = DCASE_Dataset(ANNOTATIONS_FILE, AUDIO_DIR, mel_spectrogram, SAMPLE_RATE)\n","\n","  print(f\"There are {len(dcase_data)} samples in the dataset.\")\n","\n","  signal, label, filename = dcase_data[0]\n","\n","  print(signal.shape, label, filename)\n","\n","  print(signal)\n","\n"],"execution_count":6,"outputs":[{"output_type":"stream","text":["There are 35690 samples in the dataset.\n","torch.Size([1, 64, 431]) 0 64486.wav\n","tensor([[[1.5975e-01, 2.7099e-01, 1.3740e-01,  ..., 1.6348e-02,\n","          3.1244e-02, 4.7086e-02],\n","         [3.7911e-01, 4.1791e+00, 1.7681e+00,  ..., 1.2492e+00,\n","          2.9435e-01, 1.5889e+00],\n","         [8.4830e+00, 3.1850e+00, 2.4497e+00,  ..., 3.5935e+00,\n","          1.6346e+00, 2.1412e+00],\n","         ...,\n","         [7.5682e-02, 6.5243e-02, 3.7237e-02,  ..., 2.8266e-04,\n","          6.4843e-04, 4.0049e-04],\n","         [5.4711e-02, 2.5257e-02, 2.2485e-02,  ..., 3.4433e-04,\n","          4.1962e-04, 3.1364e-04],\n","         [4.4925e-02, 1.6226e-03, 2.2030e-03,  ..., 2.1046e-04,\n","          1.6134e-04, 2.3366e-04]]])\n"],"name":"stdout"}]}]}