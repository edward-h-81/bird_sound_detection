{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"custom_dataset_dcase.ipynb","provenance":[],"authorship_tag":"ABX9TyN5tqPQLAEIP7jkOArQ1jqE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NcK7L1OA1Tgu","executionInfo":{"status":"ok","timestamp":1628145747843,"user_tz":-60,"elapsed":37391,"user":{"displayName":"Edward Hulme","photoUrl":"","userId":"12267249823946796482"}},"outputId":"39b2319e-64a3-470d-97d7-084fe88fcf9b"},"source":["# Load the Drive helper and mount\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gsefAZfHCDud","executionInfo":{"status":"ok","timestamp":1628145755414,"user_tz":-60,"elapsed":5106,"user":{"displayName":"Edward Hulme","photoUrl":"","userId":"12267249823946796482"}},"outputId":"ba6bc17f-4863-4f33-d2a7-9c487bab8257"},"source":["!pip install torchaudio"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting torchaudio\n","  Downloading torchaudio-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 4.0 MB/s \n","\u001b[?25hRequirement already satisfied: torch==1.9.0 in /usr/local/lib/python3.7/dist-packages (from torchaudio) (1.9.0+cu102)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchaudio) (3.7.4.3)\n","Installing collected packages: torchaudio\n","Successfully installed torchaudio-0.9.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1chFvuLA4EqQ","executionInfo":{"status":"ok","timestamp":1628146113809,"user_tz":-60,"elapsed":348,"user":{"displayName":"Edward Hulme","photoUrl":"","userId":"12267249823946796482"}},"outputId":"ff4989f0-3d72-42e6-81af-4ecbef5fce3c"},"source":["from torch.utils.data import Dataset\n","import pandas as pd\n","import torchaudio\n","import os\n","import librosa\n","\n","class DCASE_Dataset(Dataset):\n","\n","  def __init__(self, annotations_file, audio_dir):\n","    self.annotations = pd.read_csv(annotations_file)\n","    self.audio_dir = audio_dir\n","\n","  def __len__(self):\n","    return len(self.annotations)\n","\n","  def __getitem__(self, index):\n","    audio_sample_path = self._get_audio_sample_path(index)\n","    label = self._get_audio_sample_label(index)\n","    signal, sr = torchaudio.load(audio_sample_path) \n","    return signal, label\n","\n","  def _get_audio_sample_path(self, index):\n","    fold = f\"{self.annotations.iloc[index, 1]}\"\n","    path = os.path.join(self.audio_dir, fold, f\"{self.annotations.iloc[index, 0]}.wav\")\n","    return path\n","\n","  def _get_audio_sample_label(self, index):\n","    return self.annotations.iloc[index, 2]\n","\n","if __name__ == \"__main__\":\n","\n","  ANNOTATIONS_FILE = '/content/drive/My Drive/DCASE_Datasets/labels/ff1010bird.csv'\n","  AUDIO_DIR = '/content/drive/My Drive/DCASE_Datasets/audio/'\n","\n","  ff = DCASE_Dataset(ANNOTATIONS_FILE, AUDIO_DIR)\n","\n","  print(f\"There are {len(ff)} samples in the dataset.\")\n","\n","  signal, label = ff[0]\n","\n","  print(signal.shape, label)\n","\n","  print(signal)\n","\n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["There are 7690 samples in the dataset.\n","torch.Size([1, 441000]) 0\n","tensor([[-0.0729, -0.0900, -0.0634,  ...,  0.0149,  0.0164,  0.0174]])\n"],"name":"stdout"}]}]}