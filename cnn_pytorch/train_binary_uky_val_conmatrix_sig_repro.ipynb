{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train_binary_uky_val_conmatrix_sig_repro.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyNbZ9fsoQR0uwGthT6VuA24"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"NKnZHom2daU2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632680221292,"user_tz":-60,"elapsed":34864,"user":{"displayName":"Edward Hulme","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12267249823946796482"}},"outputId":"d2ab9e67-61b4-41cc-9036-99e42632c8f5"},"source":["# Load the Drive helper and mount\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"0Ho7hW9RdinU","executionInfo":{"status":"ok","timestamp":1632680224265,"user_tz":-60,"elapsed":218,"user":{"displayName":"Edward Hulme","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12267249823946796482"}}},"source":["import sys\n","sys.path.insert(0,'/content/drive/My Drive/MSc_Project_Colab/BAD_PyTorch/')"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HRLxTMNJecEr"},"source":["**CNN**"]},{"cell_type":"code","metadata":{"id":"dMl1PHrYdmWs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632680329237,"user_tz":-60,"elapsed":101818,"user":{"displayName":"Edward Hulme","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12267249823946796482"}},"outputId":"57ecb57c-664e-4840-9b46-b8ed3b52407d"},"source":["!pip install torchaudio librosa boto3"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torchaudio\n","  Downloading torchaudio-0.9.1-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 8.0 MB/s \n","\u001b[?25hRequirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (0.8.1)\n","Collecting boto3\n","  Downloading boto3-1.18.48-py3-none-any.whl (131 kB)\n","\u001b[K     |████████████████████████████████| 131 kB 87.6 MB/s \n","\u001b[?25hCollecting torch==1.9.1\n","  Downloading torch-1.9.1-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n","\u001b[K     |████████████████████████████████| 831.4 MB 5.2 kB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.1->torchaudio) (3.7.4.3)\n","Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (4.4.2)\n","Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.2.2)\n","Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.0.1)\n","Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.10.3.post1)\n","Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.51.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (21.0)\n","Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.5.1)\n","Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.22.2.post1)\n","Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (2.1.9)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.1)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.19.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (57.4.0)\n","Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (0.34.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa) (2.4.7)\n","Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (2.23.0)\n","Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa) (1.15.0)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa) (1.14.6)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.20)\n","Collecting jmespath<1.0.0,>=0.7.1\n","  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n","Collecting botocore<1.22.0,>=1.21.48\n","  Downloading botocore-1.21.48-py3-none-any.whl (7.9 MB)\n","\u001b[K     |████████████████████████████████| 7.9 MB 93.0 MB/s \n","\u001b[?25hCollecting s3transfer<0.6.0,>=0.5.0\n","  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 9.6 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.48->boto3) (2.8.2)\n","Collecting urllib3<1.27,>=1.25.4\n","  Downloading urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n","\u001b[K     |████████████████████████████████| 138 kB 91.4 MB/s \n","\u001b[?25h  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 63.7 MB/s \n","\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (3.0.4)\n","Installing collected packages: urllib3, jmespath, botocore, torch, s3transfer, torchaudio, boto3\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.9.0+cu102\n","    Uninstalling torch-1.9.0+cu102:\n","      Successfully uninstalled torch-1.9.0+cu102\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.10.0+cu102 requires torch==1.9.0, but you have torch 1.9.1 which is incompatible.\n","torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.9.1 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed boto3-1.18.48 botocore-1.21.48 jmespath-0.10.0 s3transfer-0.5.0 torch-1.9.1 torchaudio-0.9.1 urllib3-1.25.11\n"]}]},{"cell_type":"code","metadata":{"id":"Rxo9KzPxeZsc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632680334983,"user_tz":-60,"elapsed":5763,"user":{"displayName":"Edward Hulme","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12267249823946796482"}},"outputId":"df100cd8-9e1c-4b57-99fe-9dc35fd85a76"},"source":["from torch import nn\n","from torchsummary import summary\n","\n","\n","class CNNNetwork(nn.Module):\n","\n","    def __init__(self):\n","        super().__init__()\n","        self.conv1 = nn.Sequential(\n","            nn.Conv2d(\n","                in_channels=1,\n","                out_channels=16,\n","                kernel_size=3,\n","                stride=1,\n","                padding='valid'\n","            ),\n","            nn.BatchNorm2d(16),\n","            nn.LeakyReLU(0.001),\n","            nn.MaxPool2d(kernel_size=3)\n","        )\n","        self.conv2 = nn.Sequential(\n","            nn.Conv2d(\n","                in_channels=16,\n","                out_channels=16,\n","                kernel_size=3,\n","                stride=1,\n","                padding='valid'\n","            ),\n","            nn.BatchNorm2d(16),\n","            nn.LeakyReLU(0.001),\n","            nn.MaxPool2d(kernel_size=3)\n","        )\n","        self.conv3 = nn.Sequential(\n","            nn.Conv2d(\n","                in_channels=16,\n","                out_channels=16,\n","                kernel_size=3,\n","                stride=1,\n","                padding='valid'\n","            ),\n","            nn.BatchNorm2d(16),\n","            nn.LeakyReLU(0.001),\n","            nn.MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0)\n","        )\n","        self.conv4 = nn.Sequential(\n","            nn.Conv2d(\n","                in_channels=16,\n","                out_channels=16,\n","                kernel_size=3,\n","                stride=1,\n","                padding='valid'\n","            ),\n","            nn.BatchNorm2d(16),\n","            nn.LeakyReLU(0.001),\n","            nn.MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0)\n","        )\n","        self.flatten = nn.Flatten()\n","        self.dropout = nn.Dropout(p=0.5)\n","        self.linearA = nn.Linear(448, 256)\n","        self.batchnormA = nn.BatchNorm1d(256)\n","        self.leakyrelu = nn.LeakyReLU(0.001)\n","        self.linearB = nn.Linear(256, 32)\n","        self.batchnormB = nn.BatchNorm1d(32)\n","\n","        self.linear = nn.Linear(32, 1)\n","        # self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, input_data):\n","        x = self.conv1(input_data)\n","        x = self.conv2(x)\n","        x = self.conv3(x)\n","        x = self.conv4(x)\n","        x = self.flatten(x)\n","        x = self.dropout(x)\n","        x = self.linearA(x)\n","        x = self.batchnormA(x)\n","        x = self.leakyrelu(x)\n","        x = self.dropout(x)\n","        x = self.linearB(x)\n","        x = self.batchnormB(x)\n","        x = self.leakyrelu(x)\n","        x = self.dropout(x)\n","        logits = self.linear(x)\n","\n","        # predictions = self.sigmoid(logits)\n","        return logits\n","\n","\n","if __name__ == \"__main__\":\n","    cnn = CNNNetwork()\n","    summary(cnn.cuda(), (1, 80, 698))\n","\n"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1          [-1, 16, 78, 696]             160\n","       BatchNorm2d-2          [-1, 16, 78, 696]              32\n","         LeakyReLU-3          [-1, 16, 78, 696]               0\n","         MaxPool2d-4          [-1, 16, 26, 232]               0\n","            Conv2d-5          [-1, 16, 24, 230]           2,320\n","       BatchNorm2d-6          [-1, 16, 24, 230]              32\n","         LeakyReLU-7          [-1, 16, 24, 230]               0\n","         MaxPool2d-8            [-1, 16, 8, 76]               0\n","            Conv2d-9            [-1, 16, 6, 74]           2,320\n","      BatchNorm2d-10            [-1, 16, 6, 74]              32\n","        LeakyReLU-11            [-1, 16, 6, 74]               0\n","        MaxPool2d-12            [-1, 16, 6, 24]               0\n","           Conv2d-13            [-1, 16, 4, 22]           2,320\n","      BatchNorm2d-14            [-1, 16, 4, 22]              32\n","        LeakyReLU-15            [-1, 16, 4, 22]               0\n","        MaxPool2d-16             [-1, 16, 4, 7]               0\n","          Flatten-17                  [-1, 448]               0\n","          Dropout-18                  [-1, 448]               0\n","           Linear-19                  [-1, 256]         114,944\n","      BatchNorm1d-20                  [-1, 256]             512\n","        LeakyReLU-21                  [-1, 256]               0\n","          Dropout-22                  [-1, 256]               0\n","           Linear-23                   [-1, 32]           8,224\n","      BatchNorm1d-24                   [-1, 32]              64\n","        LeakyReLU-25                   [-1, 32]               0\n","          Dropout-26                   [-1, 32]               0\n","           Linear-27                    [-1, 1]              33\n","================================================================\n","Total params: 131,025\n","Trainable params: 131,025\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.21\n","Forward/backward pass size (MB): 22.94\n","Params size (MB): 0.50\n","Estimated Total Size (MB): 23.66\n","----------------------------------------------------------------\n"]}]},{"cell_type":"code","metadata":{"id":"UqG_xzawO4KY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632680340457,"user_tz":-60,"elapsed":5506,"user":{"displayName":"Edward Hulme","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12267249823946796482"}},"outputId":"02a56cd6-506d-49fa-f56b-7f6364f5b526"},"source":["#@title Prepare data and utility functions. {display-mode: \"form\"}\n","#@markdown\n","#@markdown You do not need to look into this cell.\n","#@markdown Just execute once and you are good to go.\n","#@markdown\n","#@markdown In this tutorial, we will use a speech data from [VOiCES dataset](https://iqtlabs.github.io/voices/), which is licensed under Creative Commos BY 4.0.\n","\n","#-------------------------------------------------------------------------------\n","# Preparation of data and helper functions.\n","#-------------------------------------------------------------------------------\n","import io\n","import os\n","import math\n","import tarfile\n","import multiprocessing\n","\n","import scipy\n","import librosa\n","import boto3\n","from botocore import UNSIGNED\n","from botocore.config import Config\n","import requests\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import time\n","from IPython.display import Audio, display\n","\n","[width, height] = matplotlib.rcParams['figure.figsize']\n","if width < 10:\n","  matplotlib.rcParams['figure.figsize'] = [width * 2.5, height]\n","\n","_SAMPLE_DIR = \"_sample_data\"\n","SAMPLE_WAV_URL = \"https://pytorch-tutorial-assets.s3.amazonaws.com/steam-train-whistle-daniel_simon.wav\"\n","SAMPLE_WAV_PATH = os.path.join(_SAMPLE_DIR, \"steam.wav\")\n","\n","SAMPLE_WAV_SPEECH_URL = \"https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/source-16k/train/sp0307/Lab41-SRI-VOiCES-src-sp0307-ch127535-sg0042.wav\"\n","SAMPLE_WAV_SPEECH_PATH = os.path.join(_SAMPLE_DIR, \"speech.wav\")\n","\n","SAMPLE_RIR_URL = \"https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/distant-16k/room-response/rm1/impulse/Lab41-SRI-VOiCES-rm1-impulse-mc01-stu-clo.wav\"\n","SAMPLE_RIR_PATH = os.path.join(_SAMPLE_DIR, \"rir.wav\")\n","\n","SAMPLE_NOISE_URL = \"https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/distant-16k/distractors/rm1/babb/Lab41-SRI-VOiCES-rm1-babb-mc01-stu-clo.wav\"\n","SAMPLE_NOISE_PATH = os.path.join(_SAMPLE_DIR, \"bg.wav\")\n","\n","SAMPLE_MP3_URL = \"https://pytorch-tutorial-assets.s3.amazonaws.com/steam-train-whistle-daniel_simon.mp3\"\n","SAMPLE_MP3_PATH = os.path.join(_SAMPLE_DIR, \"steam.mp3\")\n","\n","SAMPLE_GSM_URL = \"https://pytorch-tutorial-assets.s3.amazonaws.com/steam-train-whistle-daniel_simon.gsm\"\n","SAMPLE_GSM_PATH = os.path.join(_SAMPLE_DIR, \"steam.gsm\")\n","\n","SAMPLE_TAR_URL = \"https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit.tar.gz\"\n","SAMPLE_TAR_PATH = os.path.join(_SAMPLE_DIR, \"sample.tar.gz\")\n","SAMPLE_TAR_ITEM = \"VOiCES_devkit/source-16k/train/sp0307/Lab41-SRI-VOiCES-src-sp0307-ch127535-sg0042.wav\"\n","\n","S3_BUCKET = \"pytorch-tutorial-assets\"\n","S3_KEY = \"VOiCES_devkit/source-16k/train/sp0307/Lab41-SRI-VOiCES-src-sp0307-ch127535-sg0042.wav\"\n","\n","YESNO_DATASET_PATH = os.path.join(_SAMPLE_DIR, \"yes_no\")\n","os.makedirs(YESNO_DATASET_PATH, exist_ok=True)\n","os.makedirs(_SAMPLE_DIR, exist_ok=True)\n","\n","def _fetch_data():\n","  uri = [\n","    (SAMPLE_WAV_URL, SAMPLE_WAV_PATH),\n","    (SAMPLE_WAV_SPEECH_URL, SAMPLE_WAV_SPEECH_PATH),\n","    (SAMPLE_RIR_URL, SAMPLE_RIR_PATH),\n","    (SAMPLE_NOISE_URL, SAMPLE_NOISE_PATH),\n","    (SAMPLE_MP3_URL, SAMPLE_MP3_PATH),\n","    (SAMPLE_GSM_URL, SAMPLE_GSM_PATH),\n","    (SAMPLE_TAR_URL, SAMPLE_TAR_PATH),\n","  ]\n","  for url, path in uri:\n","    with open(path, 'wb') as file_:\n","      file_.write(requests.get(url).content)\n","\n","_fetch_data()\n","\n","def _download_yesno():\n","  if os.path.exists(os.path.join(YESNO_DATASET_PATH, \"waves_yesno.tar.gz\")):\n","    return\n","  torchaudio.datasets.YESNO(root=YESNO_DATASET_PATH, download=True)\n","\n","YESNO_DOWNLOAD_PROCESS = multiprocessing.Process(target=_download_yesno)\n","YESNO_DOWNLOAD_PROCESS.start()\n","\n","def _get_sample(path, resample=None):\n","  effects = [\n","    [\"remix\", \"1\"]\n","  ]\n","  if resample:\n","    effects.extend([\n","      [\"lowpass\", f\"{resample // 2}\"],\n","      [\"rate\", f'{resample}'],\n","    ])\n","  return torchaudio.sox_effects.apply_effects_file(path, effects=effects)\n","\n","def get_speech_sample(*, resample=None):\n","  return _get_sample(SAMPLE_WAV_SPEECH_PATH, resample=resample)\n","\n","def get_sample(*, resample=None):\n","  return _get_sample(SAMPLE_WAV_PATH, resample=resample)\n","\n","def get_rir_sample(*, resample=None, processed=False):\n","  rir_raw, sample_rate = _get_sample(SAMPLE_RIR_PATH, resample=resample)\n","  if not processed:\n","    return rir_raw, sample_rate\n","  rir = rir_raw[:, int(sample_rate*1.01):int(sample_rate*1.3)]\n","  rir = rir / torch.norm(rir, p=2)\n","  rir = torch.flip(rir, [1])\n","  return rir, sample_rate\n","\n","def get_noise_sample(*, resample=None):\n","  return _get_sample(SAMPLE_NOISE_PATH, resample=resample)\n","\n","def print_stats(waveform, sample_rate=None, src=None):\n","  if src:\n","    print(\"-\" * 10)\n","    print(\"Source:\", src)\n","    print(\"-\" * 10)\n","  if sample_rate:\n","    print(\"Sample Rate:\", sample_rate)\n","  print(\"Shape:\", tuple(waveform.shape))\n","  print(\"Dtype:\", waveform.dtype)\n","  print(f\" - Max:     {waveform.max().item():6.3f}\")\n","  print(f\" - Min:     {waveform.min().item():6.3f}\")\n","  print(f\" - Mean:    {waveform.mean().item():6.3f}\")\n","  print(f\" - Std Dev: {waveform.std().item():6.3f}\")\n","  print()\n","  print(waveform)\n","  print()\n","\n","def plot_waveform(waveform, sample_rate, title=\"Waveform\", xlim=None, ylim=None):\n","  waveform = waveform.numpy()\n","\n","  num_channels, num_frames = waveform.shape\n","  time_axis = torch.arange(0, num_frames) / sample_rate\n","\n","  figure, axes = plt.subplots(num_channels, 1)\n","  if num_channels == 1:\n","    axes = [axes]\n","  for c in range(num_channels):\n","    axes[c].plot(time_axis, waveform[c], linewidth=1)\n","    axes[c].grid(True)\n","    if num_channels > 1:\n","      axes[c].set_ylabel(f'Channel {c+1}')\n","    if xlim:\n","      axes[c].set_xlim(xlim)\n","    if ylim:\n","      axes[c].set_ylim(ylim)\n","  figure.suptitle(title)\n","  plt.show(block=False)\n","\n","def plot_specgram(waveform, sample_rate, title=\"Spectrogram\", xlim=None):\n","  waveform = waveform.numpy()\n","\n","  num_channels, num_frames = waveform.shape\n","  time_axis = torch.arange(0, num_frames) / sample_rate\n","\n","  figure, axes = plt.subplots(num_channels, 1)\n","  if num_channels == 1:\n","    axes = [axes]\n","  for c in range(num_channels):\n","    axes[c].specgram(waveform[c], Fs=sample_rate)\n","    if num_channels > 1:\n","      axes[c].set_ylabel(f'Channel {c+1}')\n","    if xlim:\n","      axes[c].set_xlim(xlim)\n","  figure.suptitle(title)\n","  plt.show(block=False)\n","\n","def play_audio(waveform, sample_rate):\n","  waveform = waveform.numpy()\n","\n","  num_channels, num_frames = waveform.shape\n","  if num_channels == 1:\n","    display(Audio(waveform[0], rate=sample_rate))\n","  elif num_channels == 2:\n","    display(Audio((waveform[0], waveform[1]), rate=sample_rate))\n","  else:\n","    raise ValueError(\"Waveform with more than 2 channels are not supported.\")\n","\n","def inspect_file(path):\n","  print(\"-\" * 10)\n","  print(\"Source:\", path)\n","  print(\"-\" * 10)\n","  print(f\" - File size: {os.path.getsize(path)} bytes\")\n","  print(f\" - {torchaudio.info(path)}\")\n","\n","def plot_spectrogram(spec, title=None, ylabel='freq_bin', aspect='auto', xmax=None):\n","  fig, axs = plt.subplots(1, 1)\n","  axs.set_title(title or 'Spectrogram (db)')\n","  axs.set_ylabel(ylabel)\n","  axs.set_xlabel('frame')\n","  im = axs.imshow(librosa.power_to_db(spec), origin='lower', aspect=aspect)\n","  if xmax:\n","    axs.set_xlim((0, xmax))\n","  fig.colorbar(im, ax=axs)\n","  plt.show(block=False)\n","\n","def plot_mel_fbank(fbank, title=None):\n","  fig, axs = plt.subplots(1, 1)\n","  axs.set_title(title or 'Filter bank')\n","  axs.imshow(fbank, aspect='auto')\n","  axs.set_ylabel('frequency bin')\n","  axs.set_xlabel('mel bin')\n","  plt.show(block=False)\n","\n","def get_spectrogram(\n","    n_fft = 400,\n","    win_len = None,\n","    hop_len = None,\n","    power = 2.0,\n","):\n","  waveform, _ = get_speech_sample()\n","  spectrogram = T.Spectrogram(\n","      n_fft=n_fft,\n","      win_length=win_len,\n","      hop_length=hop_len,\n","      center=True,\n","      pad_mode=\"reflect\",\n","      power=power,\n","  )\n","  return spectrogram(waveform)\n","\n","def plot_pitch(waveform, sample_rate, pitch):\n","  figure, axis = plt.subplots(1, 1)\n","  axis.set_title(\"Pitch Feature\")\n","  axis.grid(True)\n","\n","  end_time = waveform.shape[1] / sample_rate\n","  time_axis = torch.linspace(0, end_time,  waveform.shape[1])\n","  axis.plot(time_axis, waveform[0], linewidth=1, color='gray', alpha=0.3)\n","\n","  axis2 = axis.twinx()\n","  time_axis = torch.linspace(0, end_time, pitch.shape[1])\n","  ln2 = axis2.plot(\n","      time_axis, pitch[0], linewidth=2, label='Pitch', color='green')\n","\n","  axis2.legend(loc=0)\n","  plt.show(block=False)\n","\n","def plot_kaldi_pitch(waveform, sample_rate, pitch, nfcc):\n","  figure, axis = plt.subplots(1, 1)\n","  axis.set_title(\"Kaldi Pitch Feature\")\n","  axis.grid(True)\n","\n","  end_time = waveform.shape[1] / sample_rate\n","  time_axis = torch.linspace(0, end_time,  waveform.shape[1])\n","  axis.plot(time_axis, waveform[0], linewidth=1, color='gray', alpha=0.3)\n","\n","  time_axis = torch.linspace(0, end_time, pitch.shape[1])\n","  ln1 = axis.plot(time_axis, pitch[0], linewidth=2, label='Pitch', color='green')\n","  axis.set_ylim((-1.3, 1.3))\n","\n","  axis2 = axis.twinx()\n","  time_axis = torch.linspace(0, end_time, nfcc.shape[1])\n","  ln2 = axis2.plot(\n","      time_axis, nfcc[0], linewidth=2, label='NFCC', color='blue', linestyle='--')\n","\n","  lns = ln1 + ln2\n","  labels = [l.get_label() for l in lns]\n","  axis.legend(lns, labels, loc=0)\n","  plt.show(block=False)\n","\n","DEFAULT_OFFSET = 201\n","SWEEP_MAX_SAMPLE_RATE = 48000\n","DEFAULT_LOWPASS_FILTER_WIDTH = 6\n","DEFAULT_ROLLOFF = 0.99\n","DEFAULT_RESAMPLING_METHOD = 'sinc_interpolation'\n","\n","def _get_log_freq(sample_rate, max_sweep_rate, offset):\n","  \"\"\"Get freqs evenly spaced out in log-scale, between [0, max_sweep_rate // 2]\n","\n","  offset is used to avoid negative infinity `log(offset + x)`.\n","\n","  \"\"\"\n","  half = sample_rate // 2\n","  start, stop = math.log(offset), math.log(offset + max_sweep_rate // 2)\n","  return torch.exp(torch.linspace(start, stop, sample_rate, dtype=torch.double)) - offset\n","\n","def _get_inverse_log_freq(freq, sample_rate, offset):\n","  \"\"\"Find the time where the given frequency is given by _get_log_freq\"\"\"\n","  half = sample_rate // 2\n","  return sample_rate * (math.log(1 + freq / offset) / math.log(1 + half / offset))\n","\n","def _get_freq_ticks(sample_rate, offset, f_max):\n","  # Given the original sample rate used for generating the sweep,\n","  # find the x-axis value where the log-scale major frequency values fall in\n","  time, freq = [], []\n","  for exp in range(2, 5):\n","    for v in range(1, 10):\n","      f = v * 10 ** exp\n","      if f < sample_rate // 2:\n","        t = _get_inverse_log_freq(f, sample_rate, offset) / sample_rate\n","        time.append(t)\n","        freq.append(f)\n","  t_max = _get_inverse_log_freq(f_max, sample_rate, offset) / sample_rate\n","  time.append(t_max)\n","  freq.append(f_max)\n","  return time, freq\n","\n","def plot_sweep(waveform, sample_rate, title, max_sweep_rate=SWEEP_MAX_SAMPLE_RATE, offset=DEFAULT_OFFSET):\n","  x_ticks = [100, 500, 1000, 5000, 10000, 20000, max_sweep_rate // 2]\n","  y_ticks = [1000, 5000, 10000, 20000, sample_rate//2]\n","\n","  time, freq = _get_freq_ticks(max_sweep_rate, offset, sample_rate // 2)\n","  freq_x = [f if f in x_ticks and f <= max_sweep_rate // 2 else None for f in freq]\n","  freq_y = [f for f in freq if f >= 1000 and f in y_ticks and f <= sample_rate // 2]\n","\n","  figure, axis = plt.subplots(1, 1)\n","  axis.specgram(waveform[0].numpy(), Fs=sample_rate)\n","  plt.xticks(time, freq_x)\n","  plt.yticks(freq_y, freq_y)\n","  axis.set_xlabel('Original Signal Frequency (Hz, log scale)')\n","  axis.set_ylabel('Waveform Frequency (Hz)')\n","  axis.xaxis.grid(True, alpha=0.67)\n","  axis.yaxis.grid(True, alpha=0.67)\n","  figure.suptitle(f'{title} (sample rate: {sample_rate} Hz)')\n","  plt.show(block=True)\n","\n","def get_sine_sweep(sample_rate, offset=DEFAULT_OFFSET):\n","    max_sweep_rate = sample_rate\n","    freq = _get_log_freq(sample_rate, max_sweep_rate, offset)\n","    delta = 2 * math.pi * freq / sample_rate\n","    cummulative = torch.cumsum(delta, dim=0)\n","    signal = torch.sin(cummulative).unsqueeze(dim=0)\n","    return signal\n","\n","def benchmark_resample(\n","    method,\n","    waveform,\n","    sample_rate,\n","    resample_rate,\n","    lowpass_filter_width=DEFAULT_LOWPASS_FILTER_WIDTH,\n","    rolloff=DEFAULT_ROLLOFF,\n","    resampling_method=DEFAULT_RESAMPLING_METHOD,\n","    beta=None,\n","    librosa_type=None,\n","    iters=5\n","):\n","  if method == \"functional\":\n","    begin = time.time()\n","    for _ in range(iters):\n","      F.resample(waveform, sample_rate, resample_rate, lowpass_filter_width=lowpass_filter_width,\n","                 rolloff=rolloff, resampling_method=resampling_method)\n","    elapsed = time.time() - begin\n","    return elapsed / iters\n","  elif method == \"transforms\":\n","    resampler = T.Resample(sample_rate, resample_rate, lowpass_filter_width=lowpass_filter_width,\n","                           rolloff=rolloff, resampling_method=resampling_method, dtype=waveform.dtype)\n","    begin = time.time()\n","    for _ in range(iters):\n","      resampler(waveform)\n","    elapsed = time.time() - begin\n","    return elapsed / iters\n","  elif method == \"librosa\":\n","    waveform_np = waveform.squeeze().numpy()\n","    begin = time.time()\n","    for _ in range(iters):\n","      librosa.resample(waveform_np, sample_rate, resample_rate, res_type=librosa_type)\n","    elapsed = time.time() - begin\n","    return elapsed / iters"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["Process Process-1:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n","    self.run()\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"<ipython-input-5-02a9d5fabd2c>\", line 82, in _download_yesno\n","    torchaudio.datasets.YESNO(root=YESNO_DATASET_PATH, download=True)\n","NameError: name 'torchaudio' is not defined\n"]}]},{"cell_type":"code","metadata":{"id":"nCrTQLIEkCTL","executionInfo":{"status":"ok","timestamp":1632687108170,"user_tz":-60,"elapsed":479,"user":{"displayName":"Edward Hulme","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12267249823946796482"}}},"source":["from torch.utils.data import Dataset\n","import pandas as pd\n","import torchaudio\n","import os\n","import torch\n","\n","import matplotlib\n","import matplotlib.pyplot as plt\n","\n","import math\n","from random import randint\n","from random import uniform\n","\n","class DCASE_Dataset(Dataset):\n","\n","  def __init__(self,\n","                 annotations_file,\n","                 audio_dir,\n","                 transformation,\n","                 target_sample_rate,\n","                 num_samples,\n","                 device,\n","                 resample_device, \n","                 sig_seed, \n","                 noise_bool: bool = False,\n","                 combi_audio_bool: bool = False,\n","                 pitch_bool: bool = False,\n","                 speed_bool: bool = False):\n","    self.annotations = pd.read_csv(annotations_file)\n","    self.audio_dir = audio_dir\n","    self.device = device\n","    self.transformation = transformation.to(self.device)\n","    self.target_sample_rate = target_sample_rate\n","    self.num_samples = num_samples\n","    self.pitch_bool = pitch_bool\n","    self.noise_bool = noise_bool\n","    self.combi_audio_bool = combi_audio_bool\n","    self.speed_bool = speed_bool\n","    self.resample_device = resample_device\n","    self.sig_seed = sig_seed\n","    self.randint = randint\n","    self.uniform = uniform\n","    self.size = len(self.annotations) - 1\n","    # self.lpf_cutoff = 1000\n","\n","  def __len__(self):\n","    return len(self.annotations)\n","\n","  def __getitem__(self, index):\n","    audio_sample_path = self._get_audio_sample_path(index)\n","    label = self._get_audio_sample_label(index)\n","    # signal, sr = torchaudio.load(audio_sample_path, normalize=True) \n","\n","    if self.pitch_bool is True:\n","      pitch_val = str(randint(-200, 200))\n","      # print(pitch_val)\n","      effects = [\n","              ['gain', '-n'],\n","              ['pitch', pitch_val]  \n","      ]\n","    else:\n","      effects = [\n","        ['gain', '-n']\n","      ] \n","\n","    signal, sr = torchaudio.sox_effects.apply_effects_file(audio_sample_path, effects, channels_first=True)       \n","    if (sr % 2) != 0:\n","      sr = sr + 1\n","    # print(sr)\n","    signal = signal.to(self.device)    \n","    signal = self._resample_if_necessary(signal, sr)\n","    signal = self._mix_down_if_necessary(signal)\n","    signal = self._cut_if_necessary(signal)\n","    signal = self._right_pad_if_necessary(signal)\n","    signal = self._add_background_noise(signal)\n","    signal = self._combine_audio(signal, label)\n","    # signal = torchaudio.functional.highpass_biquad(signal, sr, cutoff_freq=self.lpf_cutoff)\n","\n","    # plot_waveform(signal.cpu(), self.target_sample_rate, title=\"Processed Audio\")\n","    # plot_specgram(signal.cpu(), self.target_sample_rate, title=\"Processed Audio\")\n","    # play_audio(signal.cpu(), self.target_sample_rate)\n","\n","    signal = self.transformation(signal) \n","    return signal, label\n","\n","  def _cut_if_necessary(self, signal):\n","      if signal.shape[1] > self.num_samples:\n","          signal = signal[:, :self.num_samples]\n","      return signal\n","\n","  def _right_pad_if_necessary(self, signal):\n","      length_signal = signal.shape[1]\n","      if length_signal < self.num_samples:\n","          num_missing_samples = self.num_samples - length_signal\n","          last_dim_padding = (0, num_missing_samples)\n","          signal = torch.nn.functional.pad(signal, last_dim_padding)\n","      return signal\n","\n","  def _resample_if_necessary(self, signal, sr):\n","    if self.speed_bool is True:\n","        if self.resample_device is 'cuda':\n","          speed_float = uniform(0.8, 1.2)\n","          speed = int(self.target_sample_rate * speed_float)\n","          if (speed % 2) != 0:\n","            speed = speed + 1\n","          # print(speed)\n","          resampler = torchaudio.transforms.Resample(sr, speed).cuda()\n","          signal = resampler(signal)\n","        else:\n","          speed_float = uniform(0.8, 1.2)\n","          speed = int(self.target_sample_rate * speed_float)\n","          if (speed % 2) != 0:\n","            speed = speed + 1\n","          resampler = torchaudio.transforms.Resample(sr, speed)\n","          signal = resampler(signal)\n","        return signal\n","    elif sr != self.target_sample_rate:\n","        if self.resample_device is 'cuda':\n","          resampler = torchaudio.transforms.Resample(sr, self.target_sample_rate).cuda()\n","          signal = resampler(signal)\n","        else:\n","          resampler = torchaudio.transforms.Resample(sr, self.target_sample_rate)\n","          signal = resampler(signal)\n","    return signal\n","\n","  def _mix_down_if_necessary(self, signal):\n","    if signal.shape[0] > 1: \n","        signal = torch.mean(signal, dim=0, keepdim=True)\n","    return signal\n","\n","  def _add_background_noise(self, signal):\n","    if self.noise_bool is False:\n","        return signal\n","    bird = signal\n","    # test code\n","    # effects_n = [\n","    #           #  ['gain', '-n']\n","    #            ]\n","\n","    noise, sr = torchaudio.load('/content/drive/My Drive/MSc_Project_Colab/pink_noise.aiff', normalize=True)\n","\n","    # test code\n","    # noise, sr = torchaudio.sox_effects.apply_effects_file('/content/drive/My Drive/MSc_Project_Colab/pink_noise.aiff', effects_n, channels_first=True)\n","    # noise = torchaudio.functional.highpass_biquad(noise, sr, cutoff_freq=self.lpf_cutoff)\n","\n","    noise = noise.to(self.device)\n","    noise = self._resample_if_necessary(noise, sr)\n","    noise = self._mix_down_if_necessary(noise)\n","    noise = self._cut_if_necessary(noise)\n","    noise = self._right_pad_if_necessary(noise)\n","\n","    # plot_waveform(noise.cpu(), self.target_sample_rate, title=\"Background noise\")\n","    # plot_specgram(noise.cpu(), self.target_sample_rate, title=\"Background noise\")\n","    # play_audio(noise.cpu(), self.target_sample_rate)\n","\n","    bird_power = bird.norm(p=2)\n","    noise_power = noise.norm(p=2)\n","\n","    snr_db = randint(3,10)\n","    snr = math.exp(snr_db / 10)\n","    scale = snr * noise_power / bird_power\n","    noisy_bird = (scale * bird + noise) / 2\n","\n","    # plot_waveform(noisy_bird.cpu(), self.target_sample_rate, title=f\"SNR: {snr_db} [dB]\")\n","    # plot_specgram(noisy_bird.cpu(), self.target_sample_rate, title=f\"SNR: {snr_db} [dB]\")\n","    # play_audio(noisy_bird.cpu(), self.target_sample_rate)\n","\n","    return noisy_bird\n","\n","  def _combine_audio(self, signal, label):\n","    if self.combi_audio_bool is False:\n","        return signal\n","\n","    rand_bird_index = self.randint(0,self.size)\n","    if label == 0 and self._get_audio_sample_label(rand_bird_index) == 1:\n","      print(f'main sound: {label}, background sound: {self._get_audio_sample_label(rand_bird_index)}')\n","      return signal\n","\n","    print(f'main sound: {label}, background sound: {self._get_audio_sample_label(rand_bird_index)}')\n","\n","    # effects_bg = [\n","    #           #  ['gain', '-n']\n","    #            ]\n","\n","    bird_main = signal\n","\n","    bird_bg = self._get_audio_sample_path(rand_bird_index)\n","    bg, sr = torchaudio.load(bird_bg, normalize=True)\n","    # bg, sr = torchaudio.sox_effects.apply_effects_file(bird_bg, effects_bg, channels_first=True)\n","    # bg = torchaudio.functional.highpass_biquad(bg, sr, cutoff_freq=self.lpf_cutoff)\n","\n","    bg = bg.to(self.device)\n","    bg = self._resample_if_necessary(bg, sr)\n","    bg = self._mix_down_if_necessary(bg)\n","    bg = self._cut_if_necessary(bg)\n","    bg = self._right_pad_if_necessary(bg)\n","\n","    # plot_waveform(bg.cpu(), self.target_sample_rate, title=\"Added audio\")\n","    # plot_specgram(bg.cpu(), self.target_sample_rate, title=\"Added audio\")\n","    # play_audio(bg.cpu(), self.target_sample_rate)\n","\n","    bird_main_power = bird_main.norm(p=2)\n","    bg_power = bg.norm(p=2)\n","\n","    \n","    snr_db = randint(3,10)\n","    snr = math.exp(snr_db / 10)\n","    scale = snr * bg_power / bird_main_power\n","    combined_sig = (scale * bird_main + bg) / 2\n","\n","    # plot_waveform(combined_sig.cpu(), self.target_sample_rate, title=f\"SNR: {snr_db} [dB]\")\n","    # plot_specgram(combined_sig.cpu(), self.target_sample_rate, title=f\"SNR: {snr_db} [dB]\")\n","    # play_audio(combined_sig.cpu(), self.target_sample_rate)\n","\n","    return combined_sig\n","\n","\n","  def _get_audio_sample_path(self, index):\n","    fold = f\"{self.annotations.iloc[index, 1]}\"\n","    path = os.path.join(self.audio_dir, fold, f\"{self.annotations.iloc[index, 0]}.wav\")\n","    print(path)\n","    return path\n","\n","  def _get_audio_sample_label(self, index):\n","    return self.annotations.iloc[index, 2]\n","\n","\n","\n","\n","  \n","\n","  \n","\n","\n"],"execution_count":25,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i66PNF3wdtgM"},"source":["Train the model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"p7fQH7h5d0pH","executionInfo":{"status":"error","timestamp":1632687272767,"user_tz":-60,"elapsed":7774,"user":{"displayName":"Edward Hulme","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12267249823946796482"}},"outputId":"537b38aa-abef-434b-8e99-af8a7760c304"},"source":["import torch\n","from torch import nn\n","from torch.utils.data import DataLoader\n","import torchaudio\n","from random import seed\n","from random import random\n","import matplotlib\n","import matplotlib.pyplot as plt\n","\n","import numpy as np\n","\n","# from dcasedataset_sig import DCASE_Dataset\n","\n","ANNOTATIONS_FILE_TRAIN = '/content/drive/My Drive/DCASE_Datasets/labels/train_val_csv/bv_ff_train.csv'\n","ANNOTATIONS_FILE_VAL = '/content/drive/My Drive/DCASE_Datasets/labels/train_val_csv/bv_ff_val.csv'\n","AUDIO_DIR = '/content/drive/My Drive/DCASE_Datasets/audio/'\n","SAMPLE_RATE = 22050\n","DURATION = 10\n","NUM_SAMPLES = 22050 * DURATION\n","RESAMPLE_DEVICE = 'cuda'\n","SIG_SEED = seed(667)\n","\n","BATCH_SIZE = 16\n","EPOCHS = 30\n","LEARNING_RATE = 0.001\n","\n","def seed_worker(worker_id):\n","    worker_seed = torch.initial_seed() % 2**32\n","    numpy.random.seed(worker_seed)\n","    random.seed(worker_seed)\n","\n","def create_data_loader(train_data, val_data, batch_size):\n","    g = torch.Generator()\n","    g.manual_seed(0)\n","\n","    train_dataloader = DataLoader(train_data, \n","                                  batch_size=batch_size,\n","                                  shuffle=True,\n","                                  num_workers=0,\n","                                  worker_init_fn=seed_worker,\n","                                  generator=g)\n","    val_dataloader = DataLoader(val_data, \n","                                batch_size=batch_size,\n","                                shuffle=True,\n","                                num_workers=0,\n","                                worker_init_fn=seed_worker,\n","                                generator=g)\n","    return train_dataloader, val_dataloader\n","\n","\n","def train_single_epoch(model, data_loader, loss_fn, optimiser, device, sigmoid):\n","    size = len(data_loader.dataset)\n","    stages_per_epoch = len(data_loader)\n","    average_loss, correct = 0, 0\n","    print(\"Dataset size: {}\".format(size))\n","    print(\"Stages per epoch {}\".format(stages_per_epoch))\n","    \n","    for input, target in data_loader:\n","        input, target = input.to(device), target.to(device)\n","\n","        # for index, signal in enumerate(input):\n","          # seed(0) SHOULD I REMOVE THIS?\n","        #   value = random()\n","\n","        #   if value > 0:\n","        #     signal = t1masking(signal)\n","        #     signal = t2masking(signal)\n","        #     signal = fmasking(signal)\n","        #     input[index] = signal\n","\n","\n","        # def plot_spectrogram(spec, title=None, ylabel='freq_bin', aspect='auto', xmax=None):\n","        #   fig, axs = plt.subplots(1, 1)\n","        #   axs.set_title(title or 'Spectrogram')\n","        #   axs.set_ylabel(ylabel)\n","        #   axs.set_xlabel('frame')\n","        #   spec = spec.cpu()\n","        #   spec = spec[0,:,:]\n","        #   im = axs.imshow(spec, origin='lower', aspect=aspect)\n","        #   if xmax:\n","        #     axs.set_xlim((0, xmax))\n","        #   fig.colorbar(im, ax=axs)\n","        #   plt.show(block=False)\n","\n","        # for signal_mod in input:\n","        #   plot_spectrogram(signal_mod)\n","\n","        # calculate train loss\n","        prediction = model(input)\n","        target = target.unsqueeze_(1)\n","        target = target.type(torch.cuda.FloatTensor)\n","        loss = loss_fn(prediction, target)\n","        print(f\"Training loss: {loss.item()}\")\n","        average_loss += loss.item()\n","\n","        # calculate train accuracy\n","        pred = sigmoid(prediction)\n","        for i, p in enumerate(pred):\n","          if p > 0.5:\n","            p = 1\n","          else:\n","            p = 0\n","          if p == target[i]:\n","            correct += 1\n","\n","        # backpropagate error and update weights\n","        optimiser.zero_grad()\n","        loss.backward()\n","        optimiser.step()\n","\n","    print(f\"Average training loss: {average_loss / stages_per_epoch}\")\n","\n","    # train data for loss graph\n","    train_loss_y.append(average_loss / stages_per_epoch)\n","    array_len = len(train_x)\n","    train_x.append(array_len)\n","\n","    # train data for accuracy graph\n","    train_acc_y.append(correct / size)\n","\n","\n","def val_single_epoch(model, data_loader, loss_fn, device, sigmoid):\n","    size = len(data_loader.dataset)\n","    stages_per_epoch = len(data_loader)\n","    print(size)\n","    print(stages_per_epoch)\n","    test_loss, correct = 0, 0\n","\n","    with torch.no_grad():\n","      for input, target in data_loader:\n","        # calculate validation loss\n","        input, target = input.to(device), target.to(device)\n","        prediction = model(input)\n","        target = target.unsqueeze_(1)\n","        target = target.type(torch.cuda.FloatTensor)\n","        loss = loss_fn(prediction, target)\n","        test_loss += loss.item()\n","        print(f\"Validation loss: {loss.item()}\")\n","\n","        # calculate val accuracy\n","        pred = sigmoid(prediction)\n","        for i, p in enumerate(pred):\n","          if p > 0.5:\n","            p = 1\n","          else:\n","            p = 0\n","          if p == target[i]:\n","            correct += 1\n","\n","    print(f\"Average validation loss: {test_loss / stages_per_epoch}\")\n","\n","    # val data for loss graph\n","    val_loss_y.append(test_loss / stages_per_epoch)\n","    array_len = len(val_x)\n","    val_x.append(array_len)\n","\n","    # val data for accuracy graph\n","    val_acc_y.append(correct / size)\n","\n","def training_and_validation(model, train_loader, val_loader, loss_fn, optimiser, device, epochs, sigmoid):\n","    for i in range(epochs):\n","        print(f\"Epoch {i+1}\")\n","        train_single_epoch(model, train_loader, loss_fn, optimiser, device, sigmoid)\n","        val_single_epoch(model, val_loader, loss_fn, device, sigmoid)\n","        print(\"---------------------------\")\n","    print(\"Finished training\")\n","\n","\n","if __name__ == \"__main__\":\n","\n","    # print(randint(0, 100))\n","\n","    # containers for metrics\n","    train_loss_y = []\n","    train_x = []\n","    val_loss_y = []\n","    val_x = []\n","    train_acc_y = []\n","    val_acc_y = []\n","\n","    # sigmoid to calculate accuracy\n","    sigmoid = nn.Sigmoid()\n","\n","    if torch.cuda.is_available():\n","        device = \"cuda\"\n","    else:\n","        device = \"cpu\"\n","    print(f\"Using {device}\")\n","\n","    # instantiate dataset object and create data loader\n","    mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n","        sample_rate=SAMPLE_RATE,\n","        n_fft=1024,\n","        hop_length=316,\n","        n_mels=80,\n","        power=0.33,\n","        normalized=True\n","    )\n","\n","    t1masking = torchaudio.transforms.TimeMasking(time_mask_param=40)\n","    t2masking = torchaudio.transforms.TimeMasking(time_mask_param=40)\n","    fmasking = torchaudio.transforms.FrequencyMasking(freq_mask_param=10)\n","\n","    train_data = DCASE_Dataset(ANNOTATIONS_FILE_TRAIN,\n","                            AUDIO_DIR,\n","                            mel_spectrogram,\n","                            SAMPLE_RATE,\n","                            NUM_SAMPLES,\n","                            device,\n","                            RESAMPLE_DEVICE,\n","                            SIG_SEED,\n","                            noise_bool=False,\n","                            combi_audio_bool=False,\n","                            pitch_bool=False,\n","                            speed_bool=False\n","                            )\n","    \n","    val_data = DCASE_Dataset(ANNOTATIONS_FILE_VAL,\n","                            AUDIO_DIR,\n","                            mel_spectrogram,\n","                            SAMPLE_RATE,\n","                            NUM_SAMPLES,\n","                            device,\n","                            RESAMPLE_DEVICE,\n","                            SIG_SEED)\n","    \n","    train_dataloader, val_dataloader = create_data_loader(train_data, val_data, BATCH_SIZE)\n","\n","    cnn = CNNNetwork().to(device)\n","    print(cnn)\n","\n","    # initialise loss funtion + optimiser\n","    # loss_fn = nn.BCELoss()\n","    loss_fn = nn.BCEWithLogitsLoss()\n","    optimiser = torch.optim.Adam(cnn.parameters(), \n","                                 lr=LEARNING_RATE)\n","\n","    # train model\n","    training_and_validation(cnn, train_dataloader, val_dataloader, loss_fn, optimiser, device, EPOCHS, sigmoid)\n","\n","    # save model\n","    torch.save(cnn.state_dict(), \"/content/drive/My Drive/MSc_Project_Colab/BAD_PyTorch/cnn.pth\")\n","    print(\"Trained cnn saved at cnn.pth\")\n","\n","    # plot the loss over train and validation dataset\n","    plt.plot(train_x, train_loss_y)\n","    plt.plot(val_x, val_loss_y)\n","    plt.xlabel(\"Epoch\")\n","    plt.ylabel(\"Loss\")\n","    plt.legend([\"Train\", \"Val\"], loc=2)\n","    plt.show()\n","\n","    # plot the accuracy over train and validation dataset\n","    plt.plot(train_x, train_acc_y)\n","    plt.plot(val_x, val_acc_y)\n","    plt.xlabel(\"Epoch\")\n","    plt.ylabel(\"Accuracy\")\n","    plt.legend([\"Train\", \"Val\"], loc=2)\n","    plt.show()"],"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Using cuda\n","CNNNetwork(\n","  (conv1): Sequential(\n","    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=valid)\n","    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): LeakyReLU(negative_slope=0.001)\n","    (3): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (conv2): Sequential(\n","    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=valid)\n","    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): LeakyReLU(negative_slope=0.001)\n","    (3): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (conv3): Sequential(\n","    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=valid)\n","    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): LeakyReLU(negative_slope=0.001)\n","    (3): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (conv4): Sequential(\n","    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=valid)\n","    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): LeakyReLU(negative_slope=0.001)\n","    (3): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n","  (dropout): Dropout(p=0.5, inplace=False)\n","  (linearA): Linear(in_features=448, out_features=256, bias=True)\n","  (batchnormA): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (leakyrelu): LeakyReLU(negative_slope=0.001)\n","  (linearB): Linear(in_features=256, out_features=32, bias=True)\n","  (batchnormB): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (linear): Linear(in_features=32, out_features=1, bias=True)\n",")\n","Epoch 1\n","Dataset size: 15921\n","Stages per epoch 996\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/56565.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/192152.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/BirdVox-DCASE-20k/47e84964-dc32-48bb-a435-58d5f8ce3edc.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/BirdVox-DCASE-20k/52118142-e0a6-453a-a492-376784c9660b.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/71694.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/55440.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/BirdVox-DCASE-20k/47649561-a524-471c-a92e-f489bbfd454d.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/BirdVox-DCASE-20k/22b76cb3-58a4-4c9a-ab69-e00faa71b8e9.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/164694.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/BirdVox-DCASE-20k/401b2624-938c-47d1-ac7a-628596eb7f68.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/149070.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/62066.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/102079.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/81271.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/181232.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/BirdVox-DCASE-20k/1f5ad8b0-fe12-4ab5-a23b-cb4755371f56.wav\n","Training loss: 0.6680649518966675\n","/content/drive/My Drive/DCASE_Datasets/audio/BirdVox-DCASE-20k/1399323b-3425-4a09-a94e-fe39f6ee3617.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/BirdVox-DCASE-20k/2e8d3e98-9e67-4ec1-a36c-51f8c6361326.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/BirdVox-DCASE-20k/4b888a02-eea5-4f5f-adb5-7a4f017b1e2d.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/BirdVox-DCASE-20k/5bd9a4bd-f78f-469f-a234-0c89f3dc143c.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/BirdVox-DCASE-20k/1196a553-2497-41b8-af41-574a8585f722.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/BirdVox-DCASE-20k/2d5cf5a2-32cb-46bf-a925-4b1de4705c87.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/28165.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/127625.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/72007.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/BirdVox-DCASE-20k/6f92044a-fb3d-443b-a0ca-5ffccb429200.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/BirdVox-DCASE-20k/72d1fdc1-968f-4924-a051-eb85968084cd.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/BirdVox-DCASE-20k/17f65882-4748-4563-a319-584460597a29.wav\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-dcb0bc7ce669>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;31m# train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m     \u001b[0mtraining_and_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimiser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;31m# save model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-26-dcb0bc7ce669>\u001b[0m in \u001b[0;36mtraining_and_validation\u001b[0;34m(model, train_loader, val_loader, loss_fn, optimiser, device, epochs, sigmoid)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {i+1}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0mtrain_single_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimiser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0mval_single_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-26-dcb0bc7ce669>\u001b[0m in \u001b[0;36mtrain_single_epoch\u001b[0;34m(model, data_loader, loss_fn, optimiser, device, sigmoid)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Stages per epoch {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstages_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-25-17c72a6b9489>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     64\u001b[0m       ] \n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0msignal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchaudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msox_effects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_effects_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_sample_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meffects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msr\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m       \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchaudio/sox_effects/sox_effects.py\u001b[0m in \u001b[0;36mapply_effects_file\u001b[0;34m(path, effects, normalize, channels_first, format)\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m     return torch.ops.torchaudio.sox_effects_apply_effects_file(\n\u001b[0;32m--> 273\u001b[0;31m         path, effects, normalize, channels_first, format)\n\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"pNb1EJW4dwM7","executionInfo":{"status":"ok","timestamp":1632686167576,"user_tz":-60,"elapsed":6608,"user":{"displayName":"Edward Hulme","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12267249823946796482"}},"outputId":"46b16ad4-bac1-493c-a477-f50e60269c6b"},"source":["import torch\n","import torchaudio\n","from torch import nn\n","\n","from random import seed\n","from random import random\n","import matplotlib\n","import matplotlib.pyplot as plt\n","\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","from sklearn.metrics import roc_curve\n","from sklearn.metrics import auc\n","import numpy as np\n","import pandas as pd\n","\n","# from dcasedatasetcpu import DCASE_Dataset\n","# from cnnbinary_uky import CNNNetwork\n","# from train_binary import ANNOTATIONS_FILE, AUDIO_DIR, SAMPLE_RATE, DURATION, NUM_SAMPLES\n","\n","ANNOTATIONS_birdvox = '/content/drive/My Drive/DCASE_Datasets/labels/BirdVox-DCASE20k.csv'\n","ANNOTATIONS_warblr = '/content/drive/My Drive/DCASE_Datasets/labels/warblrb10k.csv'\n","ANNOTATIONS_freefield = '/content/drive/My Drive/DCASE_Datasets/labels/ff1010bird.csv'\n","ANNOTATIONS_mini = '/content/drive/My Drive/DCASE_Datasets/labels/mini_metadata.csv'\n","ANNOTATIONS_bvff_1200 = '/content/drive/My Drive/DCASE_Datasets/labels/bv_ff_1200.csv'\n","AUDIO_DIR = '/content/drive/My Drive/DCASE_Datasets/audio/'\n","SAMPLE_RATE = 22050\n","DURATION = 10\n","NUM_SAMPLES = 22050 * DURATION\n","RESAMPLE_DEVICE = 'cpu'\n","THRESHOLD = 0.5\n","SIG_SEED = seed(666)\n","\n","\n","class_mapping = [\n","    \"no-bird\",\n","    \"bird\"\n","]\n","\n","\n","def predict(model, input, target, class_mapping):\n","    model.eval()\n","    with torch.no_grad():\n","        predictions = model(input).cuda()\n","        sigmoid = nn.Sigmoid()\n","        predictions = sigmoid(predictions)\n","        print(predictions)\n","        pred_float = predictions[0]\n","        # Tensor (1, 10) -> [ [0.1, 0.01, ..., 0.6] ]\n","        if predictions[0] > THRESHOLD:\n","\n","          # predicted_index = predictions[0].argmax(0)\n","          predicted_index = 1\n","        elif predictions[0] < THRESHOLD:\n","          predicted_index = 0\n","        print(predicted_index)\n","        predicted = class_mapping[predicted_index]\n","        expected = class_mapping[target]\n","    return predicted, expected, predicted_index, target, pred_float.item()\n","\n","\n","if __name__ == \"__main__\":\n","    # metrics\n","    preds = []\n","    targs = []\n","    pred_floats = []\n","\n","    # load back the model\n","    cnn = CNNNetwork()\n","    state_dict = torch.load(\"/content/drive/My Drive/MSc_Project_Colab/BAD_PyTorch/cnn.pth\", map_location=torch.device('cpu'))\n","    cnn.load_state_dict(state_dict)\n","\n","    # load DCASE dataset\n","    mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n","        sample_rate=SAMPLE_RATE,\n","        n_fft=1024,\n","        hop_length=316,\n","        n_mels=80,\n","        power=0.33,\n","        normalized=True\n","    )\n","\n","    t1masking = torchaudio.transforms.TimeMasking(time_mask_param=40)\n","    t2masking = torchaudio.transforms.TimeMasking(time_mask_param=40)\n","    fmasking = torchaudio.transforms.FrequencyMasking(freq_mask_param=10)\n","\n","    dcase = DCASE_Dataset(ANNOTATIONS_mini,\n","                            AUDIO_DIR,\n","                            mel_spectrogram,\n","                            SAMPLE_RATE,\n","                            NUM_SAMPLES,\n","                            \"cpu\",\n","                            RESAMPLE_DEVICE,\n","                            SIG_SEED)\n","\n","\n","    # get a sample from the dcase dataset for inference\n","    # num_files = len(dcase)\n","    num_files = 100\n","    seed(1)\n","    count = 0\n","    index = 0\n","    correct = 0\n","    countnobird = 0\n","    countbird = 0\n","    while count < num_files:\n","      value = random()\n","      val_label = random()\n","\n","      input, target = dcase[index][0], dcase[index][1]\n","\n","\n","      # if target == 1:\n","      #   if val_label < 0.67:\n","      #     index += 1\n","      #     continue\n","\n","      # if value > 0.5:\n","      #   input = t1masking(input)\n","      #   input = t2masking(input)\n","      #   input = fmasking(input)\n","      #   input = input\n","\n","      # def plot_spectrogram(spec, title=None, ylabel='freq_bin', aspect='auto', xmax=None):\n","      #     fig, axs = plt.subplots(1, 1)\n","      #     axs.set_title(title or 'Spectrogram')\n","      #     axs.set_ylabel(ylabel)\n","      #     axs.set_xlabel('frame')\n","      #     spec = spec.cpu()\n","      #     spec = spec[0,:,:]\n","      #     im = axs.imshow(spec, origin='lower', aspect=aspect)\n","      #     if xmax:\n","      #       axs.set_xlim((0, xmax))\n","      #     fig.colorbar(im, ax=axs)\n","      #     plt.show(block=False)\n","\n","      \n","      # plot_spectrogram(input)\n","\n","\n","      input.unsqueeze_(0)\n","\n","      index += 1\n","      count += 1\n","\n","      if target == 1:\n","        countbird += 1\n","      else:\n","        countnobird += 1\n","\n","    # make an inference\n","      predicted, expected, pred, targ, pred_float = predict(cnn, input, target,\n","                                  class_mapping)\n","      \n","      print(pred_float)\n","      \n","      preds.append(pred)\n","      targs.append(targ)\n","      pred_floats.append(pred_float)\n","\n","      if predicted == expected:\n","        correct += 1\n","      print(f\"Predicted: '{predicted}', expected: '{expected}'\")\n","      print()\n","\n","\n","    accuracy = correct / num_files\n","    print(accuracy)\n","    print(\"bird: {}\".format(countbird))\n","    print(\"no-bird: {}\".format(countnobird))\n","\n","\n","    # roc\n","    fpr, tpr, thresholds = roc_curve(targs, pred_floats)\n","    # print(\"fpr: {}, tpr: {}\".format(fpr, tpr, pos_label=2))\n","    plt.figure(1)\n","    plt.plot([0, 1], [0, 1], 'y--')\n","    plt.plot(fpr, tpr, marker='.')\n","    plt.xlabel('False positive rate')\n","    plt.ylabel('True positive rate')\n","    plt.title('ROC curve')\n","    plt.show\n","\n","    i = np.arange(len(tpr)) \n","    roc = pd.DataFrame({'tf' : pd.Series(tpr-(1-fpr), index=i), 'thresholds' : pd.Series(thresholds, index=i)})\n","    ideal_roc_thresh = roc.iloc[(roc.tf-0).abs().argsort()[:1]]  #Locate the point where the value is close to 0\n","    print(\"Ideal threshold is: \", ideal_roc_thresh['thresholds']) \n","\n","    # AUC\n","    auc_value = auc(fpr, tpr)\n","    print(\"Area under curve, AUC = \", auc_value)\n","\n","    # confusion matrix\n","    cm = confusion_matrix(targs, preds)\n","    print(cm)\n","    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"no-bird\", \"bird\"])\n","    plt.figure(2)\n","    disp.plot(values_format='') \n","\n"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/64486.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/64486.wav\n","tensor([[0.4268]], device='cuda:0')\n","0\n","0.42676112055778503\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/2525.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/2525.wav\n","tensor([[0.4290]], device='cuda:0')\n","0\n","0.4290369153022766\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/44981.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/44981.wav\n","tensor([[0.3960]], device='cuda:0')\n","0\n","0.3959560990333557\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/101323.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/101323.wav\n","tensor([[0.3583]], device='cuda:0')\n","0\n","0.35828840732574463\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/165746.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/165746.wav\n","tensor([[0.3864]], device='cuda:0')\n","0\n","0.38637202978134155\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/38232.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/38232.wav\n","tensor([[0.4445]], device='cuda:0')\n","0\n","0.44452905654907227\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/104540.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/104540.wav\n","tensor([[0.4635]], device='cuda:0')\n","0\n","0.46346956491470337\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/157473.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/157473.wav\n","tensor([[0.4685]], device='cuda:0')\n","0\n","0.46848249435424805\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/132129.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/132129.wav\n","tensor([[0.3801]], device='cuda:0')\n","0\n","0.38014093041419983\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/127302.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/127302.wav\n","tensor([[0.4102]], device='cuda:0')\n","0\n","0.41021400690078735\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/24950.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/24950.wav\n","tensor([[0.4314]], device='cuda:0')\n","0\n","0.4314066767692566\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/39924.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/39924.wav\n","tensor([[0.4512]], device='cuda:0')\n","0\n","0.45122915506362915\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/19037.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/19037.wav\n","tensor([[0.4841]], device='cuda:0')\n","0\n","0.4840909540653229\n","Predicted: 'no-bird', expected: 'bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/86729.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/86729.wav\n","tensor([[0.5183]], device='cuda:0')\n","1\n","0.5183011889457703\n","Predicted: 'bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/92992.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/92992.wav\n","tensor([[0.4377]], device='cuda:0')\n","0\n","0.43770748376846313\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/69238.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/69238.wav\n","tensor([[0.3472]], device='cuda:0')\n","0\n","0.3472270667552948\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/102853.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/102853.wav\n","tensor([[0.3773]], device='cuda:0')\n","0\n","0.37725985050201416\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/124684.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/124684.wav\n","tensor([[0.4754]], device='cuda:0')\n","0\n","0.47541239857673645\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/81068.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/81068.wav\n","tensor([[0.4556]], device='cuda:0')\n","0\n","0.45561566948890686\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/123344.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/123344.wav\n","tensor([[0.4803]], device='cuda:0')\n","0\n","0.4802594780921936\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/102553.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/102553.wav\n","tensor([[0.3158]], device='cuda:0')\n","0\n","0.31578031182289124\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/70948.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/70948.wav\n","tensor([[0.3658]], device='cuda:0')\n","0\n","0.36580130457878113\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/55122.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/55122.wav\n","tensor([[0.3628]], device='cuda:0')\n","0\n","0.3627869188785553\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/104656.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/104656.wav\n","tensor([[0.4532]], device='cuda:0')\n","0\n","0.4531826376914978\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/124698.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/124698.wav\n","tensor([[0.3435]], device='cuda:0')\n","0\n","0.3434615135192871\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/79563.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/79563.wav\n","tensor([[0.4316]], device='cuda:0')\n","0\n","0.4316490888595581\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/77649.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/77649.wav\n","tensor([[0.5575]], device='cuda:0')\n","1\n","0.557542085647583\n","Predicted: 'bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/146716.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/146716.wav\n","tensor([[0.4351]], device='cuda:0')\n","0\n","0.4350595772266388\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/146812.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/146812.wav\n","tensor([[0.4167]], device='cuda:0')\n","0\n","0.416698694229126\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/141255.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/141255.wav\n","tensor([[0.4438]], device='cuda:0')\n","0\n","0.44378402829170227\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/192790.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/192790.wav\n","tensor([[0.3276]], device='cuda:0')\n","0\n","0.3276132345199585\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/91760.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/91760.wav\n","tensor([[0.4698]], device='cuda:0')\n","0\n","0.4698316752910614\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/71838.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/71838.wav\n","tensor([[0.6048]], device='cuda:0')\n","1\n","0.604790985584259\n","Predicted: 'bird', expected: 'bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/132941.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/132941.wav\n","tensor([[0.4461]], device='cuda:0')\n","0\n","0.4460720419883728\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/97375.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/97375.wav\n","tensor([[0.4756]], device='cuda:0')\n","0\n","0.4755881428718567\n","Predicted: 'no-bird', expected: 'bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/63806.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/63806.wav\n","tensor([[0.4163]], device='cuda:0')\n","0\n","0.4162963926792145\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/38282.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/38282.wav\n","tensor([[0.3940]], device='cuda:0')\n","0\n","0.39400219917297363\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/44223.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/44223.wav\n","tensor([[0.3572]], device='cuda:0')\n","0\n","0.35720908641815186\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/72827.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/72827.wav\n","tensor([[0.4876]], device='cuda:0')\n","0\n","0.4875861704349518\n","Predicted: 'no-bird', expected: 'bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/157204.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/157204.wav\n","tensor([[0.4434]], device='cuda:0')\n","0\n","0.443362295627594\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/50678.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/50678.wav\n","tensor([[0.4609]], device='cuda:0')\n","0\n","0.4608551859855652\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/148814.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/148814.wav\n","tensor([[0.3547]], device='cuda:0')\n","0\n","0.35471776127815247\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/166175.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/166175.wav\n","tensor([[0.4733]], device='cuda:0')\n","0\n","0.4733276963233948\n","Predicted: 'no-bird', expected: 'bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/87526.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/87526.wav\n","tensor([[0.5481]], device='cuda:0')\n","1\n","0.5480528473854065\n","Predicted: 'bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/54803.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/54803.wav\n","tensor([[0.5217]], device='cuda:0')\n","1\n","0.5217471718788147\n","Predicted: 'bird', expected: 'bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/43830.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/43830.wav\n","tensor([[0.4259]], device='cuda:0')\n","0\n","0.42586973309516907\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/156039.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/156039.wav\n","tensor([[0.4299]], device='cuda:0')\n","0\n","0.4299161434173584\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/89677.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/89677.wav\n","tensor([[0.3811]], device='cuda:0')\n","0\n","0.3810562193393707\n","Predicted: 'no-bird', expected: 'bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/7885.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/7885.wav\n","tensor([[0.3364]], device='cuda:0')\n","0\n","0.33637475967407227\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/17008.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/17008.wav\n","tensor([[0.3260]], device='cuda:0')\n","0\n","0.32598763704299927\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/65676.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/65676.wav\n","tensor([[0.4070]], device='cuda:0')\n","0\n","0.40703850984573364\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/137885.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/137885.wav\n","tensor([[0.4555]], device='cuda:0')\n","0\n","0.45548152923583984\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/42805.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/42805.wav\n","tensor([[0.4771]], device='cuda:0')\n","0\n","0.47707608342170715\n","Predicted: 'no-bird', expected: 'bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/28807.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/28807.wav\n","tensor([[0.4525]], device='cuda:0')\n","0\n","0.4524920880794525\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/194705.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/194705.wav\n","tensor([[0.4298]], device='cuda:0')\n","0\n","0.4297769367694855\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/127361.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/127361.wav\n","tensor([[0.4376]], device='cuda:0')\n","0\n","0.4375542104244232\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/69090.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/69090.wav\n","tensor([[0.5826]], device='cuda:0')\n","1\n","0.5825531482696533\n","Predicted: 'bird', expected: 'bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/94833.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/94833.wav\n","tensor([[0.3410]], device='cuda:0')\n","0\n","0.3410073220729828\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/77308.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/77308.wav\n","tensor([[0.3806]], device='cuda:0')\n","0\n","0.3805672526359558\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/155250.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/155250.wav\n","tensor([[0.3999]], device='cuda:0')\n","0\n","0.3998602032661438\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/43443.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/43443.wav\n","tensor([[0.4514]], device='cuda:0')\n","0\n","0.45143449306488037\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/40130.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/40130.wav\n","tensor([[0.3701]], device='cuda:0')\n","0\n","0.3700948655605316\n","Predicted: 'no-bird', expected: 'bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/146713.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/146713.wav\n","tensor([[0.4416]], device='cuda:0')\n","0\n","0.44157832860946655\n","Predicted: 'no-bird', expected: 'bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/67419.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/67419.wav\n","tensor([[0.4244]], device='cuda:0')\n","0\n","0.4244333803653717\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/109156.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/109156.wav\n","tensor([[0.5062]], device='cuda:0')\n","1\n","0.5061743855476379\n","Predicted: 'bird', expected: 'bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/32479.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/32479.wav\n","tensor([[0.5899]], device='cuda:0')\n","1\n","0.5899066925048828\n","Predicted: 'bird', expected: 'bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/160784.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/160784.wav\n","tensor([[0.4229]], device='cuda:0')\n","0\n","0.4228751063346863\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/126154.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/126154.wav\n","tensor([[0.4257]], device='cuda:0')\n","0\n","0.4257213771343231\n","Predicted: 'no-bird', expected: 'bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/46222.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/46222.wav\n","tensor([[0.3961]], device='cuda:0')\n","0\n","0.3961179852485657\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/123144.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/123144.wav\n","tensor([[0.3962]], device='cuda:0')\n","0\n","0.3962172865867615\n","Predicted: 'no-bird', expected: 'bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/147582.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/147582.wav\n","tensor([[0.5883]], device='cuda:0')\n","1\n","0.5883430242538452\n","Predicted: 'bird', expected: 'bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/107636.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/107636.wav\n","tensor([[0.4457]], device='cuda:0')\n","0\n","0.4457080066204071\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/32261.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/32261.wav\n","tensor([[0.4487]], device='cuda:0')\n","0\n","0.4486781060695648\n","Predicted: 'no-bird', expected: 'bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/155126.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/155126.wav\n","tensor([[0.4324]], device='cuda:0')\n","0\n","0.43241557478904724\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/79704.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/79704.wav\n","tensor([[0.4572]], device='cuda:0')\n","0\n","0.4571846127510071\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/54536.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/54536.wav\n","tensor([[0.5169]], device='cuda:0')\n","1\n","0.5168700814247131\n","Predicted: 'bird', expected: 'bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/47701.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/47701.wav\n","tensor([[0.4199]], device='cuda:0')\n","0\n","0.4199015200138092\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/193483.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/193483.wav\n","tensor([[0.4453]], device='cuda:0')\n","0\n","0.4453229308128357\n","Predicted: 'no-bird', expected: 'bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/113346.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/113346.wav\n","tensor([[0.4325]], device='cuda:0')\n","0\n","0.43250635266304016\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/191373.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/191373.wav\n","tensor([[0.4298]], device='cuda:0')\n","0\n","0.4297986924648285\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/37798.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/37798.wav\n","tensor([[0.5982]], device='cuda:0')\n","1\n","0.5981979966163635\n","Predicted: 'bird', expected: 'bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/146695.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/146695.wav\n","tensor([[0.4672]], device='cuda:0')\n","0\n","0.46715620160102844\n","Predicted: 'no-bird', expected: 'bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/43444.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/43444.wav\n","tensor([[0.4106]], device='cuda:0')\n","0\n","0.41058701276779175\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/147937.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/147937.wav\n","tensor([[0.4564]], device='cuda:0')\n","0\n","0.45641767978668213\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/23771.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/23771.wav\n","tensor([[0.4727]], device='cuda:0')\n","0\n","0.47272494435310364\n","Predicted: 'no-bird', expected: 'bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/140798.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/140798.wav\n","tensor([[0.4526]], device='cuda:0')\n","0\n","0.4526197910308838\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/44048.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/44048.wav\n","tensor([[0.4086]], device='cuda:0')\n","0\n","0.4086361825466156\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/173444.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/173444.wav\n","tensor([[0.4346]], device='cuda:0')\n","0\n","0.4345715343952179\n","Predicted: 'no-bird', expected: 'bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/86763.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/86763.wav\n","tensor([[0.4405]], device='cuda:0')\n","0\n","0.4404942989349365\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/60589.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/60589.wav\n","tensor([[0.4151]], device='cuda:0')\n","0\n","0.4150547385215759\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/192681.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/192681.wav\n","tensor([[0.4204]], device='cuda:0')\n","0\n","0.420443594455719\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/80712.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/80712.wav\n","tensor([[0.4721]], device='cuda:0')\n","0\n","0.4721021354198456\n","Predicted: 'no-bird', expected: 'bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/172997.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/172997.wav\n","tensor([[0.3653]], device='cuda:0')\n","0\n","0.36532357335090637\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/65281.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/65281.wav\n","tensor([[0.4184]], device='cuda:0')\n","0\n","0.41835054755210876\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/45923.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/45923.wav\n","tensor([[0.4964]], device='cuda:0')\n","0\n","0.4963654577732086\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/78784.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/78784.wav\n","tensor([[0.4469]], device='cuda:0')\n","0\n","0.4469113349914551\n","Predicted: 'no-bird', expected: 'bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/156363.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/156363.wav\n","tensor([[0.3923]], device='cuda:0')\n","0\n","0.3923071026802063\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/41192.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/41192.wav\n","tensor([[0.4650]], device='cuda:0')\n","0\n","0.46500420570373535\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/34218.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/34218.wav\n","tensor([[0.4672]], device='cuda:0')\n","0\n","0.467162549495697\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/188172.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/188172.wav\n","tensor([[0.4412]], device='cuda:0')\n","0\n","0.44116562604904175\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","0.8\n","bird: 25\n","no-bird: 75\n","Ideal threshold is:  16    0.446911\n","Name: thresholds, dtype: float64\n","Area under curve, AUC =  0.7914666666666667\n","[[72  3]\n"," [17  8]]\n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 1080x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":["<Figure size 1080x288 with 0 Axes>"]},"metadata":{}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 1080x288 with 2 Axes>"]},"metadata":{"needs_background":"light"}}]}]}