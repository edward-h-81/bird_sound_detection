{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train_binary_uky_val_conmatrix_sig_repro.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyMILOBj6swejmrqQW4N507Z"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"NKnZHom2daU2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631979098351,"user_tz":-60,"elapsed":209,"user":{"displayName":"Edward Hulme","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12267249823946796482"}},"outputId":"62097fd4-1bb7-4cd2-d7e8-b09a02bde6c1"},"source":["# Load the Drive helper and mount\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"id":"0Ho7hW9RdinU","executionInfo":{"status":"ok","timestamp":1631979098670,"user_tz":-60,"elapsed":5,"user":{"displayName":"Edward Hulme","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12267249823946796482"}}},"source":["import sys\n","sys.path.insert(0,'/content/drive/My Drive/MSc_Project_Colab/BAD_PyTorch/')"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HRLxTMNJecEr"},"source":["**CNN**"]},{"cell_type":"code","metadata":{"id":"dMl1PHrYdmWs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631979101851,"user_tz":-60,"elapsed":3186,"user":{"displayName":"Edward Hulme","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12267249823946796482"}},"outputId":"c694785e-8010-4f28-eecc-1e08437daccb"},"source":["!pip install torchaudio librosa boto3"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torchaudio in /usr/local/lib/python3.7/dist-packages (0.9.0)\n","Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (0.8.1)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (1.18.44)\n","Requirement already satisfied: torch==1.9.0 in /usr/local/lib/python3.7/dist-packages (from torchaudio) (1.9.0+cu102)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchaudio) (3.7.4.3)\n","Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.5.1)\n","Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.2.2)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (21.0)\n","Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (2.1.9)\n","Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.0.1)\n","Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.51.2)\n","Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.10.3.post1)\n","Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.22.2.post1)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.19.5)\n","Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (4.4.2)\n","Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (0.34.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (57.4.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa) (2.4.7)\n","Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (2.23.0)\n","Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa) (1.15.0)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa) (1.14.6)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.20)\n","Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3) (0.5.0)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3) (0.10.0)\n","Requirement already satisfied: botocore<1.22.0,>=1.21.44 in /usr/local/lib/python3.7/dist-packages (from boto3) (1.21.44)\n","Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.44->boto3) (1.25.11)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.44->boto3) (2.8.2)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (3.0.4)\n"]}]},{"cell_type":"code","metadata":{"id":"Rxo9KzPxeZsc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631979105101,"user_tz":-60,"elapsed":3257,"user":{"displayName":"Edward Hulme","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12267249823946796482"}},"outputId":"2ba3989a-11ac-48a1-bf0a-2aa78cb2703c"},"source":["from torch import nn\n","from torchsummary import summary\n","\n","\n","class CNNNetwork(nn.Module):\n","\n","    def __init__(self):\n","        super().__init__()\n","        self.conv1 = nn.Sequential(\n","            nn.Conv2d(\n","                in_channels=1,\n","                out_channels=16,\n","                kernel_size=3,\n","                stride=1,\n","                padding='valid'\n","            ),\n","            nn.BatchNorm2d(16),\n","            nn.LeakyReLU(0.001),\n","            nn.MaxPool2d(kernel_size=3)\n","        )\n","        self.conv2 = nn.Sequential(\n","            nn.Conv2d(\n","                in_channels=16,\n","                out_channels=16,\n","                kernel_size=3,\n","                stride=1,\n","                padding='valid'\n","            ),\n","            nn.BatchNorm2d(16),\n","            nn.LeakyReLU(0.001),\n","            nn.MaxPool2d(kernel_size=3)\n","        )\n","        self.conv3 = nn.Sequential(\n","            nn.Conv2d(\n","                in_channels=16,\n","                out_channels=16,\n","                kernel_size=3,\n","                stride=1,\n","                padding='valid'\n","            ),\n","            nn.BatchNorm2d(16),\n","            nn.LeakyReLU(0.001),\n","            nn.MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0)\n","        )\n","        self.conv4 = nn.Sequential(\n","            nn.Conv2d(\n","                in_channels=16,\n","                out_channels=16,\n","                kernel_size=3,\n","                stride=1,\n","                padding='valid'\n","            ),\n","            nn.BatchNorm2d(16),\n","            nn.LeakyReLU(0.001),\n","            nn.MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0)\n","        )\n","        self.flatten = nn.Flatten()\n","        self.dropout = nn.Dropout(p=0.5)\n","        self.linearA = nn.Linear(448, 256)\n","        self.batchnormA = nn.BatchNorm1d(256)\n","        self.leakyrelu = nn.LeakyReLU(0.001)\n","        self.linearB = nn.Linear(256, 32)\n","        self.batchnormB = nn.BatchNorm1d(32)\n","\n","        self.linear = nn.Linear(32, 1)\n","        # self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, input_data):\n","        x = self.conv1(input_data)\n","        x = self.conv2(x)\n","        x = self.conv3(x)\n","        x = self.conv4(x)\n","        x = self.flatten(x)\n","        x = self.dropout(x)\n","        x = self.linearA(x)\n","        x = self.batchnormA(x)\n","        x = self.leakyrelu(x)\n","        x = self.dropout(x)\n","        x = self.linearB(x)\n","        x = self.batchnormB(x)\n","        x = self.leakyrelu(x)\n","        x = self.dropout(x)\n","        logits = self.linear(x)\n","\n","        # predictions = self.sigmoid(logits)\n","        return logits\n","\n","\n","if __name__ == \"__main__\":\n","    cnn = CNNNetwork()\n","    summary(cnn.cuda(), (1, 80, 698))\n","\n"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1          [-1, 16, 78, 696]             160\n","       BatchNorm2d-2          [-1, 16, 78, 696]              32\n","         LeakyReLU-3          [-1, 16, 78, 696]               0\n","         MaxPool2d-4          [-1, 16, 26, 232]               0\n","            Conv2d-5          [-1, 16, 24, 230]           2,320\n","       BatchNorm2d-6          [-1, 16, 24, 230]              32\n","         LeakyReLU-7          [-1, 16, 24, 230]               0\n","         MaxPool2d-8            [-1, 16, 8, 76]               0\n","            Conv2d-9            [-1, 16, 6, 74]           2,320\n","      BatchNorm2d-10            [-1, 16, 6, 74]              32\n","        LeakyReLU-11            [-1, 16, 6, 74]               0\n","        MaxPool2d-12            [-1, 16, 6, 24]               0\n","           Conv2d-13            [-1, 16, 4, 22]           2,320\n","      BatchNorm2d-14            [-1, 16, 4, 22]              32\n","        LeakyReLU-15            [-1, 16, 4, 22]               0\n","        MaxPool2d-16             [-1, 16, 4, 7]               0\n","          Flatten-17                  [-1, 448]               0\n","          Dropout-18                  [-1, 448]               0\n","           Linear-19                  [-1, 256]         114,944\n","      BatchNorm1d-20                  [-1, 256]             512\n","        LeakyReLU-21                  [-1, 256]               0\n","          Dropout-22                  [-1, 256]               0\n","           Linear-23                   [-1, 32]           8,224\n","      BatchNorm1d-24                   [-1, 32]              64\n","        LeakyReLU-25                   [-1, 32]               0\n","          Dropout-26                   [-1, 32]               0\n","           Linear-27                    [-1, 1]              33\n","================================================================\n","Total params: 131,025\n","Trainable params: 131,025\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.21\n","Forward/backward pass size (MB): 22.94\n","Params size (MB): 0.50\n","Estimated Total Size (MB): 23.66\n","----------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"]}]},{"cell_type":"code","metadata":{"id":"UqG_xzawO4KY","executionInfo":{"status":"ok","timestamp":1631979501310,"user_tz":-60,"elapsed":3156,"user":{"displayName":"Edward Hulme","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12267249823946796482"}}},"source":["#@title Prepare data and utility functions. {display-mode: \"form\"}\n","#@markdown\n","#@markdown You do not need to look into this cell.\n","#@markdown Just execute once and you are good to go.\n","#@markdown\n","#@markdown In this tutorial, we will use a speech data from [VOiCES dataset](https://iqtlabs.github.io/voices/), which is licensed under Creative Commos BY 4.0.\n","\n","#-------------------------------------------------------------------------------\n","# Preparation of data and helper functions.\n","#-------------------------------------------------------------------------------\n","import io\n","import os\n","import math\n","import tarfile\n","import multiprocessing\n","\n","import scipy\n","import librosa\n","import boto3\n","from botocore import UNSIGNED\n","from botocore.config import Config\n","import requests\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import time\n","from IPython.display import Audio, display\n","\n","[width, height] = matplotlib.rcParams['figure.figsize']\n","if width < 10:\n","  matplotlib.rcParams['figure.figsize'] = [width * 2.5, height]\n","\n","_SAMPLE_DIR = \"_sample_data\"\n","SAMPLE_WAV_URL = \"https://pytorch-tutorial-assets.s3.amazonaws.com/steam-train-whistle-daniel_simon.wav\"\n","SAMPLE_WAV_PATH = os.path.join(_SAMPLE_DIR, \"steam.wav\")\n","\n","SAMPLE_WAV_SPEECH_URL = \"https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/source-16k/train/sp0307/Lab41-SRI-VOiCES-src-sp0307-ch127535-sg0042.wav\"\n","SAMPLE_WAV_SPEECH_PATH = os.path.join(_SAMPLE_DIR, \"speech.wav\")\n","\n","SAMPLE_RIR_URL = \"https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/distant-16k/room-response/rm1/impulse/Lab41-SRI-VOiCES-rm1-impulse-mc01-stu-clo.wav\"\n","SAMPLE_RIR_PATH = os.path.join(_SAMPLE_DIR, \"rir.wav\")\n","\n","SAMPLE_NOISE_URL = \"https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/distant-16k/distractors/rm1/babb/Lab41-SRI-VOiCES-rm1-babb-mc01-stu-clo.wav\"\n","SAMPLE_NOISE_PATH = os.path.join(_SAMPLE_DIR, \"bg.wav\")\n","\n","SAMPLE_MP3_URL = \"https://pytorch-tutorial-assets.s3.amazonaws.com/steam-train-whistle-daniel_simon.mp3\"\n","SAMPLE_MP3_PATH = os.path.join(_SAMPLE_DIR, \"steam.mp3\")\n","\n","SAMPLE_GSM_URL = \"https://pytorch-tutorial-assets.s3.amazonaws.com/steam-train-whistle-daniel_simon.gsm\"\n","SAMPLE_GSM_PATH = os.path.join(_SAMPLE_DIR, \"steam.gsm\")\n","\n","SAMPLE_TAR_URL = \"https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit.tar.gz\"\n","SAMPLE_TAR_PATH = os.path.join(_SAMPLE_DIR, \"sample.tar.gz\")\n","SAMPLE_TAR_ITEM = \"VOiCES_devkit/source-16k/train/sp0307/Lab41-SRI-VOiCES-src-sp0307-ch127535-sg0042.wav\"\n","\n","S3_BUCKET = \"pytorch-tutorial-assets\"\n","S3_KEY = \"VOiCES_devkit/source-16k/train/sp0307/Lab41-SRI-VOiCES-src-sp0307-ch127535-sg0042.wav\"\n","\n","YESNO_DATASET_PATH = os.path.join(_SAMPLE_DIR, \"yes_no\")\n","os.makedirs(YESNO_DATASET_PATH, exist_ok=True)\n","os.makedirs(_SAMPLE_DIR, exist_ok=True)\n","\n","def _fetch_data():\n","  uri = [\n","    (SAMPLE_WAV_URL, SAMPLE_WAV_PATH),\n","    (SAMPLE_WAV_SPEECH_URL, SAMPLE_WAV_SPEECH_PATH),\n","    (SAMPLE_RIR_URL, SAMPLE_RIR_PATH),\n","    (SAMPLE_NOISE_URL, SAMPLE_NOISE_PATH),\n","    (SAMPLE_MP3_URL, SAMPLE_MP3_PATH),\n","    (SAMPLE_GSM_URL, SAMPLE_GSM_PATH),\n","    (SAMPLE_TAR_URL, SAMPLE_TAR_PATH),\n","  ]\n","  for url, path in uri:\n","    with open(path, 'wb') as file_:\n","      file_.write(requests.get(url).content)\n","\n","_fetch_data()\n","\n","def _download_yesno():\n","  if os.path.exists(os.path.join(YESNO_DATASET_PATH, \"waves_yesno.tar.gz\")):\n","    return\n","  torchaudio.datasets.YESNO(root=YESNO_DATASET_PATH, download=True)\n","\n","YESNO_DOWNLOAD_PROCESS = multiprocessing.Process(target=_download_yesno)\n","YESNO_DOWNLOAD_PROCESS.start()\n","\n","def _get_sample(path, resample=None):\n","  effects = [\n","    [\"remix\", \"1\"]\n","  ]\n","  if resample:\n","    effects.extend([\n","      [\"lowpass\", f\"{resample // 2}\"],\n","      [\"rate\", f'{resample}'],\n","    ])\n","  return torchaudio.sox_effects.apply_effects_file(path, effects=effects)\n","\n","def get_speech_sample(*, resample=None):\n","  return _get_sample(SAMPLE_WAV_SPEECH_PATH, resample=resample)\n","\n","def get_sample(*, resample=None):\n","  return _get_sample(SAMPLE_WAV_PATH, resample=resample)\n","\n","def get_rir_sample(*, resample=None, processed=False):\n","  rir_raw, sample_rate = _get_sample(SAMPLE_RIR_PATH, resample=resample)\n","  if not processed:\n","    return rir_raw, sample_rate\n","  rir = rir_raw[:, int(sample_rate*1.01):int(sample_rate*1.3)]\n","  rir = rir / torch.norm(rir, p=2)\n","  rir = torch.flip(rir, [1])\n","  return rir, sample_rate\n","\n","def get_noise_sample(*, resample=None):\n","  return _get_sample(SAMPLE_NOISE_PATH, resample=resample)\n","\n","def print_stats(waveform, sample_rate=None, src=None):\n","  if src:\n","    print(\"-\" * 10)\n","    print(\"Source:\", src)\n","    print(\"-\" * 10)\n","  if sample_rate:\n","    print(\"Sample Rate:\", sample_rate)\n","  print(\"Shape:\", tuple(waveform.shape))\n","  print(\"Dtype:\", waveform.dtype)\n","  print(f\" - Max:     {waveform.max().item():6.3f}\")\n","  print(f\" - Min:     {waveform.min().item():6.3f}\")\n","  print(f\" - Mean:    {waveform.mean().item():6.3f}\")\n","  print(f\" - Std Dev: {waveform.std().item():6.3f}\")\n","  print()\n","  print(waveform)\n","  print()\n","\n","def plot_waveform(waveform, sample_rate, title=\"Waveform\", xlim=None, ylim=None):\n","  waveform = waveform.numpy()\n","\n","  num_channels, num_frames = waveform.shape\n","  time_axis = torch.arange(0, num_frames) / sample_rate\n","\n","  figure, axes = plt.subplots(num_channels, 1)\n","  if num_channels == 1:\n","    axes = [axes]\n","  for c in range(num_channels):\n","    axes[c].plot(time_axis, waveform[c], linewidth=1)\n","    axes[c].grid(True)\n","    if num_channels > 1:\n","      axes[c].set_ylabel(f'Channel {c+1}')\n","    if xlim:\n","      axes[c].set_xlim(xlim)\n","    if ylim:\n","      axes[c].set_ylim(ylim)\n","  figure.suptitle(title)\n","  plt.show(block=False)\n","\n","def plot_specgram(waveform, sample_rate, title=\"Spectrogram\", xlim=None):\n","  waveform = waveform.numpy()\n","\n","  num_channels, num_frames = waveform.shape\n","  time_axis = torch.arange(0, num_frames) / sample_rate\n","\n","  figure, axes = plt.subplots(num_channels, 1)\n","  if num_channels == 1:\n","    axes = [axes]\n","  for c in range(num_channels):\n","    axes[c].specgram(waveform[c], Fs=sample_rate)\n","    if num_channels > 1:\n","      axes[c].set_ylabel(f'Channel {c+1}')\n","    if xlim:\n","      axes[c].set_xlim(xlim)\n","  figure.suptitle(title)\n","  plt.show(block=False)\n","\n","def play_audio(waveform, sample_rate):\n","  waveform = waveform.numpy()\n","\n","  num_channels, num_frames = waveform.shape\n","  if num_channels == 1:\n","    display(Audio(waveform[0], rate=sample_rate))\n","  elif num_channels == 2:\n","    display(Audio((waveform[0], waveform[1]), rate=sample_rate))\n","  else:\n","    raise ValueError(\"Waveform with more than 2 channels are not supported.\")\n","\n","def inspect_file(path):\n","  print(\"-\" * 10)\n","  print(\"Source:\", path)\n","  print(\"-\" * 10)\n","  print(f\" - File size: {os.path.getsize(path)} bytes\")\n","  print(f\" - {torchaudio.info(path)}\")\n","\n","def plot_spectrogram(spec, title=None, ylabel='freq_bin', aspect='auto', xmax=None):\n","  fig, axs = plt.subplots(1, 1)\n","  axs.set_title(title or 'Spectrogram (db)')\n","  axs.set_ylabel(ylabel)\n","  axs.set_xlabel('frame')\n","  im = axs.imshow(librosa.power_to_db(spec), origin='lower', aspect=aspect)\n","  if xmax:\n","    axs.set_xlim((0, xmax))\n","  fig.colorbar(im, ax=axs)\n","  plt.show(block=False)\n","\n","def plot_mel_fbank(fbank, title=None):\n","  fig, axs = plt.subplots(1, 1)\n","  axs.set_title(title or 'Filter bank')\n","  axs.imshow(fbank, aspect='auto')\n","  axs.set_ylabel('frequency bin')\n","  axs.set_xlabel('mel bin')\n","  plt.show(block=False)\n","\n","def get_spectrogram(\n","    n_fft = 400,\n","    win_len = None,\n","    hop_len = None,\n","    power = 2.0,\n","):\n","  waveform, _ = get_speech_sample()\n","  spectrogram = T.Spectrogram(\n","      n_fft=n_fft,\n","      win_length=win_len,\n","      hop_length=hop_len,\n","      center=True,\n","      pad_mode=\"reflect\",\n","      power=power,\n","  )\n","  return spectrogram(waveform)\n","\n","def plot_pitch(waveform, sample_rate, pitch):\n","  figure, axis = plt.subplots(1, 1)\n","  axis.set_title(\"Pitch Feature\")\n","  axis.grid(True)\n","\n","  end_time = waveform.shape[1] / sample_rate\n","  time_axis = torch.linspace(0, end_time,  waveform.shape[1])\n","  axis.plot(time_axis, waveform[0], linewidth=1, color='gray', alpha=0.3)\n","\n","  axis2 = axis.twinx()\n","  time_axis = torch.linspace(0, end_time, pitch.shape[1])\n","  ln2 = axis2.plot(\n","      time_axis, pitch[0], linewidth=2, label='Pitch', color='green')\n","\n","  axis2.legend(loc=0)\n","  plt.show(block=False)\n","\n","def plot_kaldi_pitch(waveform, sample_rate, pitch, nfcc):\n","  figure, axis = plt.subplots(1, 1)\n","  axis.set_title(\"Kaldi Pitch Feature\")\n","  axis.grid(True)\n","\n","  end_time = waveform.shape[1] / sample_rate\n","  time_axis = torch.linspace(0, end_time,  waveform.shape[1])\n","  axis.plot(time_axis, waveform[0], linewidth=1, color='gray', alpha=0.3)\n","\n","  time_axis = torch.linspace(0, end_time, pitch.shape[1])\n","  ln1 = axis.plot(time_axis, pitch[0], linewidth=2, label='Pitch', color='green')\n","  axis.set_ylim((-1.3, 1.3))\n","\n","  axis2 = axis.twinx()\n","  time_axis = torch.linspace(0, end_time, nfcc.shape[1])\n","  ln2 = axis2.plot(\n","      time_axis, nfcc[0], linewidth=2, label='NFCC', color='blue', linestyle='--')\n","\n","  lns = ln1 + ln2\n","  labels = [l.get_label() for l in lns]\n","  axis.legend(lns, labels, loc=0)\n","  plt.show(block=False)\n","\n","DEFAULT_OFFSET = 201\n","SWEEP_MAX_SAMPLE_RATE = 48000\n","DEFAULT_LOWPASS_FILTER_WIDTH = 6\n","DEFAULT_ROLLOFF = 0.99\n","DEFAULT_RESAMPLING_METHOD = 'sinc_interpolation'\n","\n","def _get_log_freq(sample_rate, max_sweep_rate, offset):\n","  \"\"\"Get freqs evenly spaced out in log-scale, between [0, max_sweep_rate // 2]\n","\n","  offset is used to avoid negative infinity `log(offset + x)`.\n","\n","  \"\"\"\n","  half = sample_rate // 2\n","  start, stop = math.log(offset), math.log(offset + max_sweep_rate // 2)\n","  return torch.exp(torch.linspace(start, stop, sample_rate, dtype=torch.double)) - offset\n","\n","def _get_inverse_log_freq(freq, sample_rate, offset):\n","  \"\"\"Find the time where the given frequency is given by _get_log_freq\"\"\"\n","  half = sample_rate // 2\n","  return sample_rate * (math.log(1 + freq / offset) / math.log(1 + half / offset))\n","\n","def _get_freq_ticks(sample_rate, offset, f_max):\n","  # Given the original sample rate used for generating the sweep,\n","  # find the x-axis value where the log-scale major frequency values fall in\n","  time, freq = [], []\n","  for exp in range(2, 5):\n","    for v in range(1, 10):\n","      f = v * 10 ** exp\n","      if f < sample_rate // 2:\n","        t = _get_inverse_log_freq(f, sample_rate, offset) / sample_rate\n","        time.append(t)\n","        freq.append(f)\n","  t_max = _get_inverse_log_freq(f_max, sample_rate, offset) / sample_rate\n","  time.append(t_max)\n","  freq.append(f_max)\n","  return time, freq\n","\n","def plot_sweep(waveform, sample_rate, title, max_sweep_rate=SWEEP_MAX_SAMPLE_RATE, offset=DEFAULT_OFFSET):\n","  x_ticks = [100, 500, 1000, 5000, 10000, 20000, max_sweep_rate // 2]\n","  y_ticks = [1000, 5000, 10000, 20000, sample_rate//2]\n","\n","  time, freq = _get_freq_ticks(max_sweep_rate, offset, sample_rate // 2)\n","  freq_x = [f if f in x_ticks and f <= max_sweep_rate // 2 else None for f in freq]\n","  freq_y = [f for f in freq if f >= 1000 and f in y_ticks and f <= sample_rate // 2]\n","\n","  figure, axis = plt.subplots(1, 1)\n","  axis.specgram(waveform[0].numpy(), Fs=sample_rate)\n","  plt.xticks(time, freq_x)\n","  plt.yticks(freq_y, freq_y)\n","  axis.set_xlabel('Original Signal Frequency (Hz, log scale)')\n","  axis.set_ylabel('Waveform Frequency (Hz)')\n","  axis.xaxis.grid(True, alpha=0.67)\n","  axis.yaxis.grid(True, alpha=0.67)\n","  figure.suptitle(f'{title} (sample rate: {sample_rate} Hz)')\n","  plt.show(block=True)\n","\n","def get_sine_sweep(sample_rate, offset=DEFAULT_OFFSET):\n","    max_sweep_rate = sample_rate\n","    freq = _get_log_freq(sample_rate, max_sweep_rate, offset)\n","    delta = 2 * math.pi * freq / sample_rate\n","    cummulative = torch.cumsum(delta, dim=0)\n","    signal = torch.sin(cummulative).unsqueeze(dim=0)\n","    return signal\n","\n","def benchmark_resample(\n","    method,\n","    waveform,\n","    sample_rate,\n","    resample_rate,\n","    lowpass_filter_width=DEFAULT_LOWPASS_FILTER_WIDTH,\n","    rolloff=DEFAULT_ROLLOFF,\n","    resampling_method=DEFAULT_RESAMPLING_METHOD,\n","    beta=None,\n","    librosa_type=None,\n","    iters=5\n","):\n","  if method == \"functional\":\n","    begin = time.time()\n","    for _ in range(iters):\n","      F.resample(waveform, sample_rate, resample_rate, lowpass_filter_width=lowpass_filter_width,\n","                 rolloff=rolloff, resampling_method=resampling_method)\n","    elapsed = time.time() - begin\n","    return elapsed / iters\n","  elif method == \"transforms\":\n","    resampler = T.Resample(sample_rate, resample_rate, lowpass_filter_width=lowpass_filter_width,\n","                           rolloff=rolloff, resampling_method=resampling_method, dtype=waveform.dtype)\n","    begin = time.time()\n","    for _ in range(iters):\n","      resampler(waveform)\n","    elapsed = time.time() - begin\n","    return elapsed / iters\n","  elif method == \"librosa\":\n","    waveform_np = waveform.squeeze().numpy()\n","    begin = time.time()\n","    for _ in range(iters):\n","      librosa.resample(waveform_np, sample_rate, resample_rate, res_type=librosa_type)\n","    elapsed = time.time() - begin\n","    return elapsed / iters"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"nCrTQLIEkCTL","executionInfo":{"status":"ok","timestamp":1631987304691,"user_tz":-60,"elapsed":415,"user":{"displayName":"Edward Hulme","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12267249823946796482"}}},"source":["from torch.utils.data import Dataset\n","import pandas as pd\n","import torchaudio\n","import os\n","import torch\n","\n","import matplotlib\n","import matplotlib.pyplot as plt\n","\n","import math\n","\n","class DCASE_Dataset(Dataset):\n","\n","  def __init__(self,\n","                 annotations_file,\n","                 audio_dir,\n","                 transformation,\n","                 target_sample_rate,\n","                 num_samples,\n","                 device,\n","                 noise_bool: bool = False):\n","    self.annotations = pd.read_csv(annotations_file)\n","    self.audio_dir = audio_dir\n","    self.device = device\n","    self.transformation = transformation.to(self.device)\n","    self.target_sample_rate = target_sample_rate\n","    self.num_samples = num_samples\n","    self.noise_bool = noise_bool\n","\n","  def __len__(self):\n","    return len(self.annotations)\n","\n","  def __getitem__(self, index):\n","    audio_sample_path = self._get_audio_sample_path(index)\n","    label = self._get_audio_sample_label(index)\n","    signal, sr = torchaudio.load(audio_sample_path, normalize=True) \n","\n","    # # test code\n","    effects = [\n","            ['gain', '-n']\n","            ]\n","    signal, sr = torchaudio.sox_effects.apply_effects_file(audio_sample_path, effects, channels_first=True)        \n","    signal = torchaudio.functional.highpass_biquad(signal, sr, cutoff_freq=2000)\n","\n","    signal = signal.to(self.device)    \n","    signal = self._resample_if_necessary(signal, sr)\n","    signal = self._mix_down_if_necessary(signal)\n","    signal = self._cut_if_necessary(signal)\n","    signal = self._right_pad_if_necessary(signal)\n","    signal = self._add_background_noise(signal)\n","    signal = self.transformation(signal) \n","    return signal, label\n","\n","  def _cut_if_necessary(self, signal):\n","      if signal.shape[1] > self.num_samples:\n","          signal = signal[:, :self.num_samples]\n","      return signal\n","\n","  def _right_pad_if_necessary(self, signal):\n","      length_signal = signal.shape[1]\n","      if length_signal < self.num_samples:\n","          num_missing_samples = self.num_samples - length_signal\n","          last_dim_padding = (0, num_missing_samples)\n","          signal = torch.nn.functional.pad(signal, last_dim_padding)\n","      return signal\n","\n","  def _resample_if_necessary(self, signal, sr):\n","    if sr != self.target_sample_rate:\n","        # gpu\n","        resampler = torchaudio.transforms.Resample(sr, self.target_sample_rate).cuda()\n","\n","        # cpu\n","        # resampler = torchaudio.transforms.Resample(sr, self.target_sample_rate)\n","        signal = resampler(signal)\n","    return signal\n","\n","  def _mix_down_if_necessary(self, signal):\n","    if signal.shape[0] > 1: \n","        signal = torch.mean(signal, dim=0, keepdim=True)\n","    return signal\n","\n","  def _add_background_noise(self, signal):\n","    # test code\n","    effects_n = [\n","               ['gain', '-n']\n","               ]\n","\n","    if self.noise_bool is False:\n","        return signal\n","    bird = signal\n","    # noise, sr = torchaudio.load('/content/drive/My Drive/MSc_Project_Colab/pink_noise.aiff', normalize=True)\n","\n","    # test code\n","    noise, sr = torchaudio.sox_effects.apply_effects_file('/content/drive/My Drive/MSc_Project_Colab/pink_noise.aiff', effects_n, channels_first=True)\n","    noise = torchaudio.functional.highpass_biquad(noise, sr, cutoff_freq=2000)\n","\n","    noise = noise.to(self.device)\n","    noise = self._resample_if_necessary(noise, sr)\n","    noise = self._mix_down_if_necessary(noise)\n","    noise = self._cut_if_necessary(noise)\n","    noise = self._right_pad_if_necessary(noise)\n","\n","    # plot_waveform(noise.cpu(), self.target_sample_rate, title=\"Background noise\")\n","    # plot_specgram(noise.cpu(), self.target_sample_rate, title=\"Background noise\")\n","    # play_audio(noise.cpu(), self.target_sample_rate)\n","\n","    bird_power = bird.norm(p=2)\n","    noise_power = noise.norm(p=2)\n","\n","    snr_db = 10\n","    snr = math.exp(snr_db / 10)\n","    scale = snr * noise_power / bird_power\n","    noisy_bird = (scale * bird + noise) / 2\n","\n","    # plot_waveform(noisy_bird.cpu(), self.target_sample_rate, title=f\"SNR: {snr_db} [dB]\")\n","    # plot_specgram(noisy_bird.cpu(), self.target_sample_rate, title=f\"SNR: {snr_db} [dB]\")\n","    # play_audio(noisy_bird.cpu(), self.target_sample_rate)\n","\n","    return noisy_bird\n","\n","  def _get_audio_sample_path(self, index):\n","    fold = f\"{self.annotations.iloc[index, 1]}\"\n","    path = os.path.join(self.audio_dir, fold, f\"{self.annotations.iloc[index, 0]}.wav\")\n","    print(path)\n","    return path\n","\n","  def _get_audio_sample_label(self, index):\n","    return self.annotations.iloc[index, 2]\n","\n","\n","\n","\n","  \n","\n","  \n","\n","\n"],"execution_count":99,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i66PNF3wdtgM"},"source":["Train the model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1JlJvCRAVgYbaJmkC_sAzN2J74PJXK8Jw"},"id":"p7fQH7h5d0pH","executionInfo":{"status":"error","timestamp":1631987333661,"user_tz":-60,"elapsed":21998,"user":{"displayName":"Edward Hulme","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12267249823946796482"}},"outputId":"e90cddb9-713f-414e-dc8d-f608a8b4b8dc"},"source":["import torch\n","from torch import nn\n","from torch.utils.data import DataLoader\n","import torchaudio\n","\n","from random import seed\n","from random import random\n","import matplotlib\n","import matplotlib.pyplot as plt\n","\n","import numpy as np\n","\n","# from dcasedataset_sig import DCASE_Dataset\n","\n","ANNOTATIONS_FILE_TRAIN = '/content/drive/My Drive/DCASE_Datasets/labels/mini_metadata.csv'\n","ANNOTATIONS_FILE_VAL = '/content/drive/My Drive/DCASE_Datasets/labels/mini_metadata.csv'\n","AUDIO_DIR = '/content/drive/My Drive/DCASE_Datasets/audio/'\n","SAMPLE_RATE = 22050\n","DURATION = 10\n","NUM_SAMPLES = 22050 * DURATION\n","\n","\n","BATCH_SIZE = 16\n","EPOCHS = 30\n","LEARNING_RATE = 0.001\n","\n","def seed_worker(worker_id):\n","    worker_seed = torch.initial_seed() % 2**32\n","    numpy.random.seed(worker_seed)\n","    random.seed(worker_seed)\n","\n","def create_data_loader(train_data, val_data, batch_size):\n","    g = torch.Generator()\n","    g.manual_seed(0)\n","\n","    train_dataloader = DataLoader(train_data, \n","                                  batch_size=batch_size,\n","                                  shuffle=True,\n","                                  num_workers=0,\n","                                  worker_init_fn=seed_worker,\n","                                  generator=g)\n","    val_dataloader = DataLoader(val_data, batch_size=batch_size)\n","    return train_dataloader, val_dataloader\n","\n","\n","def train_single_epoch(model, data_loader, loss_fn, optimiser, device, sigmoid):\n","    size = len(data_loader.dataset)\n","    stages_per_epoch = len(data_loader)\n","    average_loss, correct = 0, 0\n","    print(\"Dataset size: {}\".format(size))\n","    print(\"Stages per epoch {}\".format(stages_per_epoch))\n","    \n","    for input, target in data_loader:\n","        input, target = input.to(device), target.to(device)\n","\n","        for index, signal in enumerate(input):\n","          # seed(1)\n","          value = random()\n","\n","        #   if value > 0:\n","        #     signal = t1masking(signal)\n","        #     signal = t2masking(signal)\n","        #     signal = fmasking(signal)\n","        #     input[index] = signal\n","\n","\n","        # def plot_spectrogram(spec, title=None, ylabel='freq_bin', aspect='auto', xmax=None):\n","        #   fig, axs = plt.subplots(1, 1)\n","        #   axs.set_title(title or 'Spectrogram')\n","        #   axs.set_ylabel(ylabel)\n","        #   axs.set_xlabel('frame')\n","        #   spec = spec.cpu()\n","        #   spec = spec[0,:,:]\n","        #   im = axs.imshow(spec, origin='lower', aspect=aspect)\n","        #   if xmax:\n","        #     axs.set_xlim((0, xmax))\n","        #   fig.colorbar(im, ax=axs)\n","        #   plt.show(block=False)\n","\n","        # for signal_mod in input:\n","        #   plot_spectrogram(signal_mod)\n","\n","        # calculate train loss\n","        prediction = model(input)\n","        target = target.unsqueeze_(1)\n","        target = target.type(torch.cuda.FloatTensor)\n","        loss = loss_fn(prediction, target)\n","        print(f\"Training loss: {loss.item()}\")\n","        average_loss += loss.item()\n","\n","        # calculate train accuracy\n","        pred = sigmoid(prediction)\n","        for i, p in enumerate(pred):\n","          if p > 0.5:\n","            p = 1\n","          else:\n","            p = 0\n","          if p == target[i]:\n","            correct += 1\n","\n","        # backpropagate error and update weights\n","        optimiser.zero_grad()\n","        loss.backward()\n","        optimiser.step()\n","\n","    print(f\"Average training loss: {average_loss / stages_per_epoch}\")\n","\n","    # train data for loss graph\n","    train_loss_y.append(average_loss / stages_per_epoch)\n","    array_len = len(train_x)\n","    train_x.append(array_len)\n","\n","    # train data for accuracy graph\n","    train_acc_y.append(correct / size)\n","\n","\n","def val_single_epoch(model, data_loader, loss_fn, device, sigmoid):\n","    size = len(data_loader.dataset)\n","    stages_per_epoch = len(data_loader)\n","    print(size)\n","    print(stages_per_epoch)\n","    test_loss, correct = 0, 0\n","\n","    with torch.no_grad():\n","      for input, target in data_loader:\n","        # calculate validation loss\n","        input, target = input.to(device), target.to(device)\n","        prediction = model(input)\n","        target = target.unsqueeze_(1)\n","        target = target.type(torch.cuda.FloatTensor)\n","        loss = loss_fn(prediction, target)\n","        test_loss += loss.item()\n","        print(f\"Validation loss: {loss.item()}\")\n","\n","        # calculate val accuracy\n","        pred = sigmoid(prediction)\n","        for i, p in enumerate(pred):\n","          if p > 0.5:\n","            p = 1\n","          else:\n","            p = 0\n","          if p == target[i]:\n","            correct += 1\n","\n","    print(f\"Average validation loss: {test_loss / stages_per_epoch}\")\n","\n","    # val data for loss graph\n","    val_loss_y.append(test_loss / stages_per_epoch)\n","    array_len = len(val_x)\n","    val_x.append(array_len)\n","\n","    # val data for accuracy graph\n","    val_acc_y.append(correct / size)\n","\n","def training_and_validation(model, train_loader, val_loader, loss_fn, optimiser, device, epochs, sigmoid):\n","    for i in range(epochs):\n","        print(f\"Epoch {i+1}\")\n","        train_single_epoch(model, train_loader, loss_fn, optimiser, device, sigmoid)\n","        val_single_epoch(model, val_loader, loss_fn, device, sigmoid)\n","        print(\"---------------------------\")\n","    print(\"Finished training\")\n","\n","\n","if __name__ == \"__main__\":\n","\n","    # containers for metrics\n","    train_loss_y = []\n","    train_x = []\n","    val_loss_y = []\n","    val_x = []\n","    train_acc_y = []\n","    val_acc_y = []\n","\n","    # sigmoid to calculate accuracy\n","    sigmoid = nn.Sigmoid()\n","\n","    if torch.cuda.is_available():\n","        device = \"cuda\"\n","    else:\n","        device = \"cpu\"\n","    print(f\"Using {device}\")\n","\n","    # instantiate dataset object and create data loader\n","    mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n","        sample_rate=SAMPLE_RATE,\n","        n_fft=1024,\n","        hop_length=316,\n","        n_mels=80,\n","        power=0.33,\n","        normalized=True\n","    )\n","\n","    t1masking = torchaudio.transforms.TimeMasking(time_mask_param=40)\n","    t2masking = torchaudio.transforms.TimeMasking(time_mask_param=40)\n","    fmasking = torchaudio.transforms.FrequencyMasking(freq_mask_param=10)\n","\n","    train_data = DCASE_Dataset(ANNOTATIONS_FILE_TRAIN,\n","                            AUDIO_DIR,\n","                            mel_spectrogram,\n","                            SAMPLE_RATE,\n","                            NUM_SAMPLES,\n","                            device,\n","                            noise_bool=True)\n","    \n","    val_data = DCASE_Dataset(ANNOTATIONS_FILE_VAL,\n","                            AUDIO_DIR,\n","                            mel_spectrogram,\n","                            SAMPLE_RATE,\n","                            NUM_SAMPLES,\n","                            device)\n","    \n","    train_dataloader, val_dataloader = create_data_loader(train_data, val_data, BATCH_SIZE)\n","\n","    cnn = CNNNetwork().to(device)\n","    print(cnn)\n","\n","    # initialise loss funtion + optimiser\n","    # loss_fn = nn.BCELoss()\n","    loss_fn = nn.BCEWithLogitsLoss()\n","    optimiser = torch.optim.Adam(cnn.parameters(), \n","                                 lr=LEARNING_RATE)\n","\n","    # train model\n","    training_and_validation(cnn, train_dataloader, val_dataloader, loss_fn, optimiser, device, EPOCHS, sigmoid)\n","\n","    # save model\n","    torch.save(cnn.state_dict(), \"/content/drive/My Drive/MSc_Project_Colab/BAD_PyTorch/cnn.pth\")\n","    print(\"Trained cnn saved at cnn.pth\")\n","\n","    # plot the loss over train and validation dataset\n","    plt.plot(train_x, train_loss_y)\n","    plt.plot(val_x, val_loss_y)\n","    plt.xlabel(\"Epoch\")\n","    plt.ylabel(\"Loss\")\n","    plt.legend([\"Train\", \"Val\"], loc=2)\n","    plt.show()\n","\n","    # plot the accuracy over train and validation dataset\n","    plt.plot(train_x, train_acc_y)\n","    plt.plot(val_x, val_acc_y)\n","    plt.xlabel(\"Epoch\")\n","    plt.ylabel(\"Accuracy\")\n","    plt.legend([\"Train\", \"Val\"], loc=2)\n","    plt.show()"],"execution_count":100,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"pNb1EJW4dwM7","executionInfo":{"status":"ok","timestamp":1631986266382,"user_tz":-60,"elapsed":9535,"user":{"displayName":"Edward Hulme","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12267249823946796482"}},"outputId":"4058cb74-32ba-498d-8fe1-41b90297b3a6"},"source":["import torch\n","import torchaudio\n","from torch import nn\n","\n","from random import seed\n","from random import random\n","import matplotlib\n","import matplotlib.pyplot as plt\n","\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","from sklearn.metrics import roc_curve\n","from sklearn.metrics import auc\n","import numpy as np\n","import pandas as pd\n","\n","# from dcasedatasetcpu import DCASE_Dataset\n","# from cnnbinary_uky import CNNNetwork\n","# from train_binary import ANNOTATIONS_FILE, AUDIO_DIR, SAMPLE_RATE, DURATION, NUM_SAMPLES\n","\n","ANNOTATIONS_birdvox = '/content/drive/My Drive/DCASE_Datasets/labels/BirdVox-DCASE20k.csv'\n","ANNOTATIONS_warblr = '/content/drive/My Drive/DCASE_Datasets/labels/warblrb10k.csv'\n","ANNOTATIONS_freefield = '/content/drive/My Drive/DCASE_Datasets/labels/ff1010bird.csv'\n","ANNOTATIONS_mini = '/content/drive/My Drive/DCASE_Datasets/labels/mini_metadata.csv'\n","ANNOTATIONS_bvff_1200 = '/content/drive/My Drive/DCASE_Datasets/labels/bv_ff_1200.csv'\n","AUDIO_DIR = '/content/drive/My Drive/DCASE_Datasets/audio/'\n","SAMPLE_RATE = 22050\n","DURATION = 10\n","NUM_SAMPLES = 22050 * DURATION\n","THRESHOLD = 0.389085\n","\n","\n","class_mapping = [\n","    \"no-bird\",\n","    \"bird\"\n","]\n","\n","\n","def predict(model, input, target, class_mapping):\n","    model.eval()\n","    with torch.no_grad():\n","        predictions = model(input).cuda()\n","        sigmoid = nn.Sigmoid()\n","        predictions = sigmoid(predictions)\n","        print(predictions)\n","        pred_float = predictions[0]\n","        # Tensor (1, 10) -> [ [0.1, 0.01, ..., 0.6] ]\n","        if predictions[0] > THRESHOLD:\n","\n","          # predicted_index = predictions[0].argmax(0)\n","          predicted_index = 1\n","        elif predictions[0] < THRESHOLD:\n","          predicted_index = 0\n","        print(predicted_index)\n","        predicted = class_mapping[predicted_index]\n","        expected = class_mapping[target]\n","    return predicted, expected, predicted_index, target, pred_float.item()\n","\n","\n","if __name__ == \"__main__\":\n","    # metrics\n","    preds = []\n","    targs = []\n","    pred_floats = []\n","\n","    # load back the model\n","    cnn = CNNNetwork()\n","    state_dict = torch.load(\"/content/drive/My Drive/MSc_Project_Colab/BAD_PyTorch/cnn.pth\", map_location=torch.device('cpu'))\n","    cnn.load_state_dict(state_dict)\n","\n","    # load DCASE dataset\n","    mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n","        sample_rate=SAMPLE_RATE,\n","        n_fft=1024,\n","        hop_length=316,\n","        n_mels=80,\n","        power=0.33,\n","        normalized=True\n","    )\n","\n","    t1masking = torchaudio.transforms.TimeMasking(time_mask_param=40)\n","    t2masking = torchaudio.transforms.TimeMasking(time_mask_param=40)\n","    fmasking = torchaudio.transforms.FrequencyMasking(freq_mask_param=10)\n","\n","    dcase = DCASE_Dataset(ANNOTATIONS_mini,\n","                            AUDIO_DIR,\n","                            mel_spectrogram,\n","                            SAMPLE_RATE,\n","                            NUM_SAMPLES,\n","                            \"cpu\",\n","                            noise_bool=False)\n","\n","\n","    # get a sample from the dcase dataset for inference\n","    # num_files = len(dcase)\n","    num_files = 100\n","    seed(1)\n","    count = 0\n","    index = 0\n","    correct = 0\n","    countnobird = 0\n","    countbird = 0\n","    while count < num_files:\n","      value = random()\n","      val_label = random()\n","\n","      input, target = dcase[index][0], dcase[index][1]\n","\n","\n","      # if target == 1:\n","      #   if val_label < 0.67:\n","      #     index += 1\n","      #     continue\n","\n","      # if value > 0.5:\n","      #   input = t1masking(input)\n","      #   input = t2masking(input)\n","      #   input = fmasking(input)\n","      #   input = input\n","\n","      # def plot_spectrogram(spec, title=None, ylabel='freq_bin', aspect='auto', xmax=None):\n","      #     fig, axs = plt.subplots(1, 1)\n","      #     axs.set_title(title or 'Spectrogram')\n","      #     axs.set_ylabel(ylabel)\n","      #     axs.set_xlabel('frame')\n","      #     spec = spec.cpu()\n","      #     spec = spec[0,:,:]\n","      #     im = axs.imshow(spec, origin='lower', aspect=aspect)\n","      #     if xmax:\n","      #       axs.set_xlim((0, xmax))\n","      #     fig.colorbar(im, ax=axs)\n","      #     plt.show(block=False)\n","\n","      \n","      # plot_spectrogram(input)\n","\n","\n","      input.unsqueeze_(0)\n","\n","      index += 1\n","      count += 1\n","\n","      if target == 1:\n","        countbird += 1\n","      else:\n","        countnobird += 1\n","\n","    # make an inference\n","      predicted, expected, pred, targ, pred_float = predict(cnn, input, target,\n","                                  class_mapping)\n","      \n","      print(pred_float)\n","      \n","      preds.append(pred)\n","      targs.append(targ)\n","      pred_floats.append(pred_float)\n","\n","      if predicted == expected:\n","        correct += 1\n","      print(f\"Predicted: '{predicted}', expected: '{expected}'\")\n","      print()\n","\n","\n","    accuracy = correct / num_files\n","    print(accuracy)\n","    print(\"bird: {}\".format(countbird))\n","    print(\"no-bird: {}\".format(countnobird))\n","\n","\n","    # roc\n","    fpr, tpr, thresholds = roc_curve(targs, pred_floats)\n","    # print(\"fpr: {}, tpr: {}\".format(fpr, tpr, pos_label=2))\n","    plt.figure(1)\n","    plt.plot([0, 1], [0, 1], 'y--')\n","    plt.plot(fpr, tpr, marker='.')\n","    plt.xlabel('False positive rate')\n","    plt.ylabel('True positive rate')\n","    plt.title('ROC curve')\n","    plt.show\n","\n","    i = np.arange(len(tpr)) \n","    roc = pd.DataFrame({'tf' : pd.Series(tpr-(1-fpr), index=i), 'thresholds' : pd.Series(thresholds, index=i)})\n","    ideal_roc_thresh = roc.iloc[(roc.tf-0).abs().argsort()[:1]]  #Locate the point where the value is close to 0\n","    print(\"Ideal threshold is: \", ideal_roc_thresh['thresholds']) \n","\n","    # AUC\n","    auc_value = auc(fpr, tpr)\n","    print(\"Area under curve, AUC = \", auc_value)\n","\n","    # confusion matrix\n","    cm = confusion_matrix(targs, preds)\n","    print(cm)\n","    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"no-bird\", \"bird\"])\n","    plt.figure(2)\n","    disp.plot(values_format='') \n","\n"],"execution_count":89,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/64486.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/64486.wav\n","tensor([[0.1864]], device='cuda:0')\n","0\n","0.18636342883110046\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/2525.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/2525.wav\n","tensor([[0.0502]], device='cuda:0')\n","0\n","0.050179898738861084\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/44981.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/44981.wav\n","tensor([[0.1866]], device='cuda:0')\n","0\n","0.18660452961921692\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/101323.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/101323.wav\n","tensor([[0.1669]], device='cuda:0')\n","0\n","0.16686847805976868\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/165746.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/165746.wav\n","tensor([[0.1623]], device='cuda:0')\n","0\n","0.16230852901935577\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/38232.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/38232.wav\n","tensor([[0.0760]], device='cuda:0')\n","0\n","0.07595410943031311\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/104540.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/104540.wav\n","tensor([[0.1006]], device='cuda:0')\n","0\n","0.10062705725431442\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/157473.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/157473.wav\n","tensor([[0.0981]], device='cuda:0')\n","0\n","0.09810733795166016\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/132129.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/132129.wav\n","tensor([[0.0863]], device='cuda:0')\n","0\n","0.08634672313928604\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/127302.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/127302.wav\n","tensor([[0.2023]], device='cuda:0')\n","0\n","0.20233765244483948\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/24950.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/24950.wav\n","tensor([[0.1079]], device='cuda:0')\n","0\n","0.10794980823993683\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/39924.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/39924.wav\n","tensor([[0.0734]], device='cuda:0')\n","0\n","0.07335209846496582\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/19037.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/19037.wav\n","tensor([[0.2994]], device='cuda:0')\n","0\n","0.29938405752182007\n","Predicted: 'no-bird', expected: 'bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/86729.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/86729.wav\n","tensor([[0.1558]], device='cuda:0')\n","0\n","0.1558494120836258\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/92992.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/92992.wav\n","tensor([[0.0813]], device='cuda:0')\n","0\n","0.0813315361738205\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/69238.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/69238.wav\n","tensor([[0.2196]], device='cuda:0')\n","0\n","0.21961863338947296\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/102853.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/102853.wav\n","tensor([[0.1174]], device='cuda:0')\n","0\n","0.11740192770957947\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/124684.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/124684.wav\n","tensor([[0.1538]], device='cuda:0')\n","0\n","0.15383334457874298\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/81068.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/81068.wav\n","tensor([[0.1257]], device='cuda:0')\n","0\n","0.1257377564907074\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/123344.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/123344.wav\n","tensor([[0.0907]], device='cuda:0')\n","0\n","0.09071670472621918\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/102553.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/102553.wav\n","tensor([[0.2410]], device='cuda:0')\n","0\n","0.24098320305347443\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/70948.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/70948.wav\n","tensor([[0.1363]], device='cuda:0')\n","0\n","0.13625992834568024\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/55122.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/55122.wav\n","tensor([[0.1136]], device='cuda:0')\n","0\n","0.11364908516407013\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/104656.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/104656.wav\n","tensor([[0.1128]], device='cuda:0')\n","0\n","0.11281086504459381\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/124698.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/124698.wav\n","tensor([[0.1993]], device='cuda:0')\n","0\n","0.19927442073822021\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/79563.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/79563.wav\n","tensor([[0.1061]], device='cuda:0')\n","0\n","0.10611642897129059\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/77649.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/77649.wav\n","tensor([[0.0722]], device='cuda:0')\n","0\n","0.07223111391067505\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/146716.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/146716.wav\n","tensor([[0.0850]], device='cuda:0')\n","0\n","0.08503042906522751\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/146812.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/146812.wav\n","tensor([[0.0761]], device='cuda:0')\n","0\n","0.07610896974802017\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/141255.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/141255.wav\n","tensor([[0.1875]], device='cuda:0')\n","0\n","0.18747004866600037\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/192790.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/192790.wav\n","tensor([[0.0609]], device='cuda:0')\n","0\n","0.06085183843970299\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/91760.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/91760.wav\n","tensor([[0.2149]], device='cuda:0')\n","0\n","0.21492375433444977\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/71838.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/71838.wav\n","tensor([[0.9430]], device='cuda:0')\n","1\n","0.9429562091827393\n","Predicted: 'bird', expected: 'bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/132941.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/132941.wav\n","tensor([[0.1819]], device='cuda:0')\n","0\n","0.18191277980804443\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/97375.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/97375.wav\n","tensor([[0.3853]], device='cuda:0')\n","0\n","0.3852957487106323\n","Predicted: 'no-bird', expected: 'bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/63806.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/63806.wav\n","tensor([[0.0957]], device='cuda:0')\n","0\n","0.09565901756286621\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/38282.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/38282.wav\n","tensor([[0.0529]], device='cuda:0')\n","0\n","0.05285239219665527\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/44223.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/44223.wav\n","tensor([[0.1802]], device='cuda:0')\n","0\n","0.18015016615390778\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/72827.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/72827.wav\n","tensor([[0.4966]], device='cuda:0')\n","1\n","0.49656397104263306\n","Predicted: 'bird', expected: 'bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/157204.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/157204.wav\n","tensor([[0.0822]], device='cuda:0')\n","0\n","0.08220666646957397\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/50678.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/50678.wav\n","tensor([[0.0689]], device='cuda:0')\n","0\n","0.06888904422521591\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/148814.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/148814.wav\n","tensor([[0.1119]], device='cuda:0')\n","0\n","0.11191705614328384\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/166175.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/166175.wav\n","tensor([[0.2500]], device='cuda:0')\n","0\n","0.2500094771385193\n","Predicted: 'no-bird', expected: 'bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/87526.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/87526.wav\n","tensor([[0.0496]], device='cuda:0')\n","0\n","0.04962979257106781\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/54803.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/54803.wav\n","tensor([[0.8365]], device='cuda:0')\n","1\n","0.8365354537963867\n","Predicted: 'bird', expected: 'bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/43830.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/43830.wav\n","tensor([[0.0635]], device='cuda:0')\n","0\n","0.06345109641551971\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/156039.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/156039.wav\n","tensor([[0.1059]], device='cuda:0')\n","0\n","0.1059490442276001\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/89677.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/89677.wav\n","tensor([[0.2791]], device='cuda:0')\n","0\n","0.27911409735679626\n","Predicted: 'no-bird', expected: 'bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/7885.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/7885.wav\n","tensor([[0.0751]], device='cuda:0')\n","0\n","0.07512815296649933\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/17008.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/17008.wav\n","tensor([[0.1837]], device='cuda:0')\n","0\n","0.18366476893424988\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/65676.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/65676.wav\n","tensor([[0.1995]], device='cuda:0')\n","0\n","0.199452206492424\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/137885.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/137885.wav\n","tensor([[0.0739]], device='cuda:0')\n","0\n","0.07394266873598099\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/42805.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/42805.wav\n","tensor([[0.1029]], device='cuda:0')\n","0\n","0.10290142148733139\n","Predicted: 'no-bird', expected: 'bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/28807.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/28807.wav\n","tensor([[0.0471]], device='cuda:0')\n","0\n","0.047091856598854065\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/194705.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/194705.wav\n","tensor([[0.0872]], device='cuda:0')\n","0\n","0.0872378945350647\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/127361.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/127361.wav\n","tensor([[0.0512]], device='cuda:0')\n","0\n","0.05124225094914436\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/69090.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/69090.wav\n","tensor([[0.8694]], device='cuda:0')\n","1\n","0.8694329261779785\n","Predicted: 'bird', expected: 'bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/94833.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/94833.wav\n","tensor([[0.2040]], device='cuda:0')\n","0\n","0.20398695766925812\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/77308.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/77308.wav\n","tensor([[0.0668]], device='cuda:0')\n","0\n","0.06679442524909973\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/155250.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/155250.wav\n","tensor([[0.1177]], device='cuda:0')\n","0\n","0.11765877902507782\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/43443.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/43443.wav\n","tensor([[0.0943]], device='cuda:0')\n","0\n","0.09428887069225311\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/40130.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/40130.wav\n","tensor([[0.2822]], device='cuda:0')\n","0\n","0.2822350263595581\n","Predicted: 'no-bird', expected: 'bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/146713.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/146713.wav\n","tensor([[0.0689]], device='cuda:0')\n","0\n","0.06886298209428787\n","Predicted: 'no-bird', expected: 'bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/67419.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/67419.wav\n","tensor([[0.0616]], device='cuda:0')\n","0\n","0.061637766659259796\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/109156.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/109156.wav\n","tensor([[0.5197]], device='cuda:0')\n","1\n","0.5196989178657532\n","Predicted: 'bird', expected: 'bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/32479.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/32479.wav\n","tensor([[0.8700]], device='cuda:0')\n","1\n","0.8699880838394165\n","Predicted: 'bird', expected: 'bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/160784.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/160784.wav\n","tensor([[0.0670]], device='cuda:0')\n","0\n","0.06695806235074997\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/126154.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/126154.wav\n","tensor([[0.1048]], device='cuda:0')\n","0\n","0.10482662171125412\n","Predicted: 'no-bird', expected: 'bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/46222.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/46222.wav\n","tensor([[0.0851]], device='cuda:0')\n","0\n","0.08513469249010086\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/123144.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/123144.wav\n","tensor([[0.1477]], device='cuda:0')\n","0\n","0.14765077829360962\n","Predicted: 'no-bird', expected: 'bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/147582.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/147582.wav\n","tensor([[0.8154]], device='cuda:0')\n","1\n","0.8154301643371582\n","Predicted: 'bird', expected: 'bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/107636.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/107636.wav\n","tensor([[0.1832]], device='cuda:0')\n","0\n","0.1832391917705536\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/32261.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/32261.wav\n","tensor([[0.4406]], device='cuda:0')\n","1\n","0.44058579206466675\n","Predicted: 'bird', expected: 'bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/155126.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/155126.wav\n","tensor([[0.0563]], device='cuda:0')\n","0\n","0.05629148706793785\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/79704.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/79704.wav\n","tensor([[0.0540]], device='cuda:0')\n","0\n","0.05401219055056572\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/54536.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/54536.wav\n","tensor([[0.7796]], device='cuda:0')\n","1\n","0.7796191573143005\n","Predicted: 'bird', expected: 'bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/47701.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/47701.wav\n","tensor([[0.0804]], device='cuda:0')\n","0\n","0.08039508759975433\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/193483.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/193483.wav\n","tensor([[0.0594]], device='cuda:0')\n","0\n","0.05940684676170349\n","Predicted: 'no-bird', expected: 'bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/113346.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/113346.wav\n","tensor([[0.0604]], device='cuda:0')\n","0\n","0.06044154241681099\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/191373.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/191373.wav\n","tensor([[0.0800]], device='cuda:0')\n","0\n","0.07995406538248062\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/37798.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/37798.wav\n","tensor([[0.8699]], device='cuda:0')\n","1\n","0.8698899745941162\n","Predicted: 'bird', expected: 'bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/146695.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/146695.wav\n","tensor([[0.3652]], device='cuda:0')\n","0\n","0.36521828174591064\n","Predicted: 'no-bird', expected: 'bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/43444.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/43444.wav\n","tensor([[0.1150]], device='cuda:0')\n","0\n","0.11504080146551132\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/147937.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/147937.wav\n","tensor([[0.0748]], device='cuda:0')\n","0\n","0.07483882457017899\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/23771.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/23771.wav\n","tensor([[0.3289]], device='cuda:0')\n","0\n","0.32893678545951843\n","Predicted: 'no-bird', expected: 'bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/140798.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/140798.wav\n","tensor([[0.0785]], device='cuda:0')\n","0\n","0.07845211029052734\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/44048.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/44048.wav\n","tensor([[0.0738]], device='cuda:0')\n","0\n","0.07384252548217773\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/173444.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/173444.wav\n","tensor([[0.1952]], device='cuda:0')\n","0\n","0.19524332880973816\n","Predicted: 'no-bird', expected: 'bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/86763.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/86763.wav\n","tensor([[0.0577]], device='cuda:0')\n","0\n","0.05767502263188362\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/60589.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/60589.wav\n","tensor([[0.2095]], device='cuda:0')\n","0\n","0.20952394604682922\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/192681.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/192681.wav\n","tensor([[0.0724]], device='cuda:0')\n","0\n","0.07237572968006134\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/80712.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/80712.wav\n","tensor([[0.1907]], device='cuda:0')\n","0\n","0.19070172309875488\n","Predicted: 'no-bird', expected: 'bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/172997.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/172997.wav\n","tensor([[0.1365]], device='cuda:0')\n","0\n","0.13648125529289246\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/65281.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/65281.wav\n","tensor([[0.2042]], device='cuda:0')\n","0\n","0.20422473549842834\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/45923.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/45923.wav\n","tensor([[0.1977]], device='cuda:0')\n","0\n","0.19770367443561554\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/78784.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/78784.wav\n","tensor([[0.6038]], device='cuda:0')\n","1\n","0.6038298010826111\n","Predicted: 'bird', expected: 'bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/156363.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/156363.wav\n","tensor([[0.1509]], device='cuda:0')\n","0\n","0.15087635815143585\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/41192.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/41192.wav\n","tensor([[0.1080]], device='cuda:0')\n","0\n","0.10798684507608414\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/34218.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/34218.wav\n","tensor([[0.2487]], device='cuda:0')\n","0\n","0.24868929386138916\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/188172.wav\n","/content/drive/My Drive/DCASE_Datasets/audio/ff1010bird/188172.wav\n","tensor([[0.0653]], device='cuda:0')\n","0\n","0.06530746072530746\n","Predicted: 'no-bird', expected: 'no-bird'\n","\n","0.86\n","bird: 25\n","no-bird: 75\n","Ideal threshold is:  4    0.190702\n","Name: thresholds, dtype: float64\n","Area under curve, AUC =  0.8698666666666666\n","[[75  0]\n"," [14 11]]\n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 1080x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":["<Figure size 1080x288 with 0 Axes>"]},"metadata":{}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAWgAAAEGCAYAAABIGw//AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAbFUlEQVR4nO3de5hcVZnv8e8vTQIEyT3EKMFwGxAVAuaAiDJRdARHBnQAQYaJHDyI93HGo+jMg8jMeNDRwzgIaBAlyP0iBES5GOQ63EKMGBIwgtwTcoFIACFJ9zt/7FVJpemq2kWqq1anf5/n2U/t69pvp+Dt1WuvtbYiAjMzy8+QTgdgZmZ9c4I2M8uUE7SZWaacoM3MMuUEbWaWqc06HUCnjRvTFZMnDe10GNaE398/vNMhWBNe5kVWxyvqdByNfOA9W8WKZ7tLnXvf/a9cHxEH9nNITtCTJw3lnusndToMa8IH3jCl0yFYE+6O2Z0OoZQVz3Zzz/XblTq3a+Kicf0cDuAEbWYGQAA99HQ6jA04QZuZAUGwJso1cbSLE7SZWeIatJlZhoKgO7OpL5ygzcySHpygzcyyE0C3E7SZWZ5cgzYzy1AAa9wGbWaWnyDcxGFmlqWA7rzysydLMjODykjCcksjknaRNK9qeV7SP0gaI+lGSYvS5+h65ThBm5kBILpLLo1ExEMRMSUipgBvB14CrgROBGZHxM7A7LRdkxO0mRmVh4QqtTTpAODhiHgMOASYmfbPBA6td6HboM3MqPSDLp18x0maU7U9IyJm1Dj3SOCitD4hIhan9SXAhHo3cYI2M0t6yteOl0fE1EYnSRoG/A3w1d7HIiIk1X0s6QRtZkbTNeiyDgLmRsQzafsZSRMjYrGkicDSehe7DdrMDAhEN0NKLU04ivXNGwBXA9PT+nRgVr2LXYM2M0uaaOJoSNJWwPuBT1btPhW4VNJxwGPAEfXKcII2M6OoQa+OrtaVF/EiMLbXvhUUvTpKcYI2M6MyUCWvVl8naDOzpB8eEm4UJ2gzMyBCdIdr0GZmWepxDdrMLD/FQ8K8UmJe0ZiZdYgfEpqZZay7hf2gW8EJ2syM9SMJc+IEbWaW9LgXh5lZforJkpygzcyyE4g1LRzq3QpO0GZmQAQeqGJmlid5oIqZWY4C16DNzLLlh4RmZhkK1NIJ+1vBCdrMjKKJY43n4jAzy5E8H7SZWY4CjyQ0M8tWbjXovH5dmJl1SIToiSGlljIkjZJ0uaQHJS2UtK+kMZJulLQofY6uV4YTtJkZlYeEXaWWkr4HXBcRuwJ7AAuBE4HZEbEzMDtt1+QEbWYGQPFOwjJLw5KkkcD+wDkAEbE6IlYChwAz02kzgUPrleM2aDMzKg8JS7dBj5M0p2p7RkTMqNreHlgG/ETSHsB9wBeACRGxOJ2zBJhQ7yZO0GZmSRMjCZdHxNQ6xzcD9gI+FxF3S/oevZozIiIkRb2buInDzIz1IwnLLCU8CTwZEXen7cspEvYzkiYCpM+l9QpxgjYzS3oYUmppJCKWAE9I2iXtOgBYAFwNTE/7pgOz6pXjJg4zM4r5oNf0tLTO+jngAknDgEeAYykqxZdKOg54DDiiXgFO0GZmVJo4WpegI2Ie0Fc79QFly3CCNjNLchtJ6AS9CXjiD5vzzRMmr9te8vgwjvm/S3jxT1388sIxjBzTDcCxX32avQ9Y1aEorZap057nhH99mq4hwS8vGsOl36/b88r6SZPd7Noi2wQt6YWIeF0f+08Bbo2IXzW4fhrwpYj4UD+FmI1JO73CWb96CIDubjh6r7ew30ErueHisXz4/yzj8E8t63CEVsuQIcFnvvkUXz1yB5YvHsrpv1jEXdeP5PFFW3Q6tEGotU0crZBtgq4lIk7qa7+krojobnc8uZl329ZMfNMrTNh2TadDsRJ22fMlnn50GEse3xyAm2eNYt8P/MkJukNyeydhv/26kDQ5TRBytqQHJN0gaUtJUyTdJel+SVfWmyxE0mnp2tmSxqd950o6LK0/KulbkuYCh0s6ME1MMhf4SH/9bDm7edYoph26ct32NT8ZzwkH7MJ3vziJVSvzeqW8wdjXr2HZ08PWbS9fPJRxE/3LtROKXhxdpZZ26e/6/M7AGRHxFmAl8LfAecBXImJ34HfA12tcuxUwJ117S53zVkTEXsBVwNnAwcDbgdfXCkrS8ZLmSJqzbMWmU+les1rcdcNI9j+4SNAfmr6cn9y5gDNvfIgxE9Yw4xtv6HCEZvlq8UCVlujvBP3H1NUEirHoOwKjIuKWtG8mxYQifekBLknr5wPvqnFe5Zxd0/0WRUSka/oUETMiYmpETB0/dtOpVd5709bs9LaXGD1+LQCjx6+lqwuGDIGDjn6Wh+YN73CE1tuKJUMZ/4bV67bHTVzD8sVDOxjR4NaDSi3t0t8J+pWq9W5gVF8nSeqSNC8tp9Qoq9aY9Rc3JsBNyc1Xjd6geWPFM+sfMfz3L0cyeZeXOxGW1fHQvOG8cfvVTJj0CpsN7WHaISu564aRnQ5rUKr04sipBt3uh4R/Ap6T9O6IuA04BrglPdyb0uvcIcBhwMXAx4DbG5T9IDBZ0o4R8TBwVGtDz9vLLw1h7m1b84VvP7Fu3zn/9gYefmBLJJiw7Wo+X3XM8tDTLc745zfyzQsfYUgX3HDxGB77vR8Qdop7cRTjz38gaTjrhz/25UVgb0n/QjGhyEfrFRoRL0s6HrhW0kvAbcDWrQs7b1sM7+HyB+ZvsO/Lpz/eoWisGffeNIJ7bxrR6TAGvQixdrAk6Ih4FHhr1fZ3qg6/o8T1r+oDnfZ/vGp9cq9j11G0RZuZNc0DVczMMuSRhGZmGXOCNjPLUKUfdE6coM3MktyGejtBm5lRDPVe29oJ+zeaE7SZWeImDjOzDLkN2swsY+EEbWaWJz8kNDPLUERr26AlPQqsopgobm1ETJU0hmIGzsnAo8AREfFcrTLyemRpZtYxortnSKmlCe+JiCkRUXm794nA7IjYGZidtmtygjYzSyJUatkIh1DMg0/6PLTeyU7QZmY0PR/0uMpbmdJyfI0ib5B0X9XxCRGxOK0vAeq+wt1t0GZmAFG0Q5e0vKrZopZ3RcRTkrYBbpT04Aa3iwhJde/oGrSZWdLKV15FxFPpcylwJbA38IykiQDpc2m9MpygzcwoBqq06iGhpK0kbV1ZB/4KmA9cTfHSEtLnrHrluInDzCxpoomjkQnAlZKgyLMXRsR1ku4FLpV0HPAYcES9QpygzcySVo0kjIhHgD362L8COKBsOU7QZmYUtWcP9TYzy5QnSzIzy1QL26BbwgnazIw03agn7Dczy1NmFWgnaDMzII0kdBu0mVmeMqtCO0GbmSUDpgYt6XTq/D6JiM/3S0RmZh0QQE/PAEnQwJy2RWFm1mkBDJQadETMrN6WNDwiXur/kMzMOiO3ftANO/1J2lfSAuDBtL2HpDP7PTIzs3aLkkublOmV/Z/AB4AVABHxW2D//gzKzKz9yr3uqp0PEkv14oiIJ9K0eRXd/ROOmVkHZdbEUSZBPyHpnUBIGgp8AVjYv2GZmbVZQGTWi6NME8cJwGeANwJPA1PStpnZJkYll/ZoWIOOiOXA0W2IxcysszJr4ijTi2MHSddIWiZpqaRZknZoR3BmZm01AHtxXAhcCkwE3gBcBlzUn0GZmbVdZaBKmaVNyiTo4RHx04hYm5bzgS36OzAzs3YrXnvVeGmXmgla0hhJY4BfSjpR0mRJb5L0ZeAX7QvRzKxNelRuKUFSl6TfSPp52t5e0t2S/iDpEknDGpVR7yHhfRSV/ko0n6w6FsBXS0VpZjZAqLW140qX5BFp+1vAaRFxsaQfAMcBZ9UroGYNOiK2j4gd0mfvxQ8JzWzTUvYBYYkkLmlb4K+BH6VtAe8FLk+nzAQObVROqZGEkt4K7EZV23NEnFfmWjOzgaGpB4DjJFXP+DkjImZUbf8n8GVg67Q9FlgZEWvT9pMUY0vqapigJX0dmEaRoH8BHATcDjhBm9mmpXwTx/KImNrXAUkfApZGxH2Spm1MOGVq0IcBewC/iYhjJU0Azt+Ym5qZZamnJaXsB/yNpA9StDqMAL4HjJK0WapFbws81aigMt3s/hwRPcBaSSOApcCk1xy6mVmOWtQPOiK+GhHbRsRk4Ejgpog4Gvg1RYUXYDowq1FIZRL0HEmjgLMpenbMBe4scZ2Z2YCiKLe8Rl8B/lHSHyjapM9pdEGZuTg+nVZ/IOk6YERE3P+aQzQzy1WLB6FExM3AzWn9EWDvZq6v99LYveodi4i5zdzIzMyaU68G/d06x4KiT9+A9/tHxvL+jx7b6TCsCV17ru50CNaMB+/odASltXigykar99LY97QzEDOzjgpKD+Nul1IDVczMBoWBUoM2MxtsBkwTh5nZoJNZgi7zRhVJ+jtJJ6Xt7SQ11VXEzGxAGIBvVDkT2Bc4Km2vAs7ot4jMzDqg7CCVdjaDlGni2Cci9pL0G4CIeK7MRNNmZgPOAOzFsUZSF6liL2k8rZpSxMwsI7k9JCzTxPFfwJXANpL+nWKq0W/2a1RmZp2QWRt0mbk4LpB0H3AAxeuvDo2Ihf0emZlZO7W5fbmMMhP2bwe8BFxTvS8iHu/PwMzM2m6gJWjgWta/PHYLYHvgIeAt/RiXmVnbKbOna2WaON5WvZ1muft0jdPNzKxFmh5JGBFzJe3TH8GYmXXUQGvikPSPVZtDgL2Ap/stIjOzThiIDwlZ/9pwgLUUbdJX9E84ZmYdNJASdBqgsnVEfKlN8ZiZdc5ASdCV14NL2q+dAZmZdYIYWL047qFob54n6WrgMuDFysGI+Fk/x2Zm1j4tbIOWtAVwK7A5RZ69PCK+Lml74GKKt3rfBxwTETXf4VZmqPcWwAqKdxB+CDg4fZqZbVpaN9T7FeC9EbEHMAU4UNI7gG8Bp0XETsBzwHH1CqlXg94m9eCYz/qBKtU/hpnZpqVFmS0iAnghbQ5NS+Vl2x9L+2cCJwNn1SqnXoLuAl7Hhol53f2bC9fMLH9NNHGMkzSnantGRMzYoKyik8V9wE4Uc+g/DKyMiLXplCeBN9a7Sb0EvTgiTikdrpnZQFc+QS+PiKl1i4roBqZIGkUxI+iuzYZTL0HnNXO1mVl/iv7pxRERKyX9muLNVKMqPeSAbYGn6l1b7yHhAS2M0cwsfy16SChpfKo5I2lL4P3AQuDXwGHptOnArHrl1KxBR8SzjcMwM9t0tHCo90RgZmqHHgJcGhE/l7QAuFjSvwG/Ac6pV0jTkyWZmW2yWteL435gzz72PwLsXbYcJ2gzM2j766zKcII2MyMN9XaCNjPLkxO0mVmunKDNzDLlBG1mlqEB+kYVM7PBwQnazCxPA2nCfjOzQcVNHGZmOfJAFTOzjDlBm5nlxyMJzcwypp68MrQTtJkZuA3azCxnbuIwM8uVE7SZWZ5cgzYzy5UTtJlZhvrprd4bwwnazIw8+0EP6XQAZmbZiCi3NCBpkqRfS1og6QFJX0j7x0i6UdKi9Dm6XjlO0GZmiaLcUsJa4J8iYjfgHcBnJO0GnAjMjoidgdlpuyYn6E3AP51wO5fOuJgZ37nqVccO+9B8brzkXEZs/XIHIrNavviFu7j4giv4wRnXrtv37nc9zg/PvJZfXHMhO++0ooPRDVLRxNKoqIjFETE3ra8CFgJvBA4BZqbTZgKH1isn2wQtabKk+X3s/1H6TdTo+o9L+n7/RJeXG27Zia/9v/e/av/4sS/y9t2f5pllW3UgKqvnxl/twL+c9J4N9j362Ej+9d/fzfz523QoKlNPuQUYJ2lO1XJ8zTKlycCewN3AhIhYnA4tASbUiyfbBF1LRHwiIhb03i+pqxPx5OB3C1/PqheGvWr/CX9/D2dfMLVMk5m12fwHtmHVqg2/syeeGMmTT43oUEQGTSXo5RExtWqZ0Wd50uuAK4B/iIjnq49FRMP6eO4JejNJF0haKOlyScMl3SxpKoCkFyR9V9JvgX0lHSvp95LuAfbrbOidte/Ux1nx7HAeeWxMp0MxGxiClj0kBJA0lCI5XxARP0u7n5E0MR2fCCytV0buCXoX4MyIeDPwPPDpXse3Au6OiD2Ah4FvUCTmdwE1m0EkHV/502T1mhf7J/IO2nzYWo469H7OvXTPTodiNqC06iGhJAHnAAsj4v9XHboamJ7WpwOz6pWTe4J+IiLuSOvnUyTeat0Uv6EA9gFujohlEbEauKRWoRExo/KnybChm1777MQJq3j9Ni/ww2/P4qenX8b4sS9x1qnXMHrkS50OzSxvLXpISFFRPAZ4r6R5afkgcCrwfkmLgPel7ZpyH6jS+5+i9/bLEdHdrmAGikefGM0Rxx+5bvunp1/GZ752MM+v2qKDUZnlrZUDVSLi9lRkXw4oW07uCXo7SftGxJ3Ax4DbgYNrnHs38D1JYymaQw4HftueMDvra5+/hd13W8LIrV/mwjMv5bzLpnDdr/+i02FZHSd++Q52f9szjBjxCj+deSXnX7A7q1YN41MnzGHkyFc45eRbeOSRUfzzSe/tdKiDR4Qn7G/SQxQdvH8MLADOokaCjojFkk4G7gRWAvPaFWSnffO//rLu8WM+d3ibIrGyTv1238+w//vOSW2OxDaQV37ON0FHxKPArn0cmlZ1zut6XfMT4Cf9GpiZbbJym4sj2wRtZtZWAbiJw8wsU3nlZydoM7MKN3GYmWXKvTjMzHJUfhBK2zhBm5lRGaiSV4Z2gjYzq/A7Cc3M8uQatJlZjtwGbWaWK8/FYWaWLzdxmJllKNa9ziobTtBmZhWuQZuZZSqv/OwEbWZWoZ682jicoM3MIE032ukgNuQEbWYGiMhuoErub/U2M2ufiHJLA5J+LGmppPlV+8ZIulHSovQ5ulE5TtBmZhUtStDAucCBvfadCMyOiJ2B2Wm7LidoMzNY3wZdZmlUVMStwLO9dh8CzEzrM4FDG5XjNmgzs6SJXhzjJM2p2p4RETMaXDMhIhan9SXAhEY3cYI2MwOgdPMFwPKImPqa7xQRUuMXbLmJw8wM0mx2LWuD7sszkiYCpM+ljS5wgjYzq2hRG3QNVwPT0/p0YFajC9zEYWaWtKoftKSLgGkUbdVPAl8HTgUulXQc8BhwRKNynKDNzCpalKAj4qgahw5ophwnaDMzKJJzd15jvZ2gzcwqMhvq7QRtZlbhBG1mlqEA/E5CM7McBYTboM3M8hP4IaGZWbbcBm1mliknaDOzHG3UPBv9wgnazAxSLw63QZuZ5ck1aDOzHHmot5lZngLC/aDNzDLlkYRmZplyG7SZWYYi3IvDzCxbrkGbmeUoiO7uTgexASdoMzPwdKNmZlnLrJvdkE4HYGaWgwCiJ0otZUg6UNJDkv4g6cTXEpMTtJkZFA8Io6fc0oCkLuAM4CBgN+AoSbs1G5KbOMzMkhY+JNwb+ENEPAIg6WLgEGBBM4UoMutW0m6SlgGPdTqOfjAOWN7pIKwpm+p39qaIGN/pIBqRdB3Fd1DGFsDLVdszImJGVVmHAQdGxCfS9jHAPhHx2WZiGvQ16IHwH85rIWlOREztdBxWnr+zzoqIAzsdQ29ugzYza72ngElV29umfU1xgjYza717gZ0lbS9pGHAkcHWzhQz6Jo5N2IzGp1hm/J1tIiJiraTPAtcDXcCPI+KBZssZ9A8Jzcxy5SYOM7NMOUGbmWXKCXoTJOmFGvtPkfS+EtdPk/Tz1kc2eEmaLGl+H/t/VGaEmaSPS/p+/0RnufJDwkEkIk7qa7+krojIa57FQaIykKE3fycGrkFnKdW2Fko6W9IDkm6QtKWkKZLuknS/pCslja5Txmnp2tmSxqd956YRTkh6VNK3JM0FDk8TuzyYtj/Snp900NlM0gXpu71c0nBJN0uaCsVfPpK+K+m3wL6SjpX0e0n3APt1NnTrBCfofO0MnBERbwFWAn8LnAd8JSJ2B34HfL3GtVsBc9K1t9Q5b0VE7AVcBZwNHAy8HXh9y34Kq7YLcGZEvBl4Hvh0r+NbAXdHxB7Aw8A3KBLzuygm3LFBxgk6X3+MiHlp/T5gR2BURNyS9s0E9q9xbQ9wSVo/n+J/8L5Uztk13W9RFP0uz9+oyK2WJyLijrTe1/fSDVyR1vcBbo6IZRGxmvXflQ0iTtD5eqVqvRsY1ddJkrokzUvLKTXKqtXZ/cWNCdCa1vt76L39studrZoT9MDxJ+A5Se9O28cAt0REd0RMSUvlIeAQ4LC0/jHg9gZlPwhMlrRj2j6qlYHbOttJ2jetN/pe7gb+UtJYSUOBw/s9OsuOE/TAMh34D0n3A1OAWjXmF4G9U7eu99Y5D4CIeBk4Hrg2PSRc2rqQrcpDwGckLQRGA2fVOjEiFgMnA3cCdwAL2xGg5cVDvc3MMuUatJlZppygzcwy5QRtZpYpJ2gzs0w5QZuZZcoJ2uqS1J0GwcyXdJmk4RtRVvVcIHVncUsz6r3zNdzjUUmvejNzrf29zulzFsA6558s6UvNxmhWlhO0NfLnNAjmrcBq4ITqg5Je04yIEfGJiFhQ55RpQNMJ2mxT4gRtzbgN2CnVbm+TdDWwIA03/w9J96aZ9j4JoML3JT0k6VfANpWCes3idqCkuZJ+m2bfm0zxi+CLqfb+bknjJV2R7nGvpP3StWPTbH8PSPoRoEY/hKSrJN2Xrjm+17G+ZgHcUdJ16ZrbJO3ain9Ms0Y8H7SVkmrKBwHXpV17AW+NiD+mJPeniPhfkjYH7pB0A7AnxQxuuwETgAXAj3uVO55iJr39U1ljIuJZST8AXoiI76TzLgROi4jbJW1H8TLON1PM1Hd7RJwi6a+B40r8OP873WNL4F5JV0TECtbPAvhFSSelsj9L8TLXEyJikaR9gDMpRmia9SsnaGtkS0mVWfVuA86haHq4JyL+mPb/FbB7pX0ZGEkxXer+wEVpAqCnJd3UR/nvAG6tlBURz9aI433AbtK6CvIISa9L9/hIuvZaSc+V+Jk+L+nDaX1SinUFr54F8GfpHu8ELqu69+Yl7mG20ZygrZE/R8SU6h0pUVXPhCfgcxFxfa/zPtjCOIYA70jzhvSOpTRJ0yiS/b4R8ZKkm4Etapwe6b4re/8bmLWD26CtFa4HPpVmXUPSX0jaCrgV+Ghqo54IvKePa+8C9pe0fbp2TNq/Cti66rwbgM9VNiRVEuatFDPDIekgikmI6hkJPJeS864UNfiKV80CGBHPA3+UdHi6hyTt0eAeZi3hBG2t8COK9uW5aQa9H1L8dXYlsCgdO49iZrYNRMQyipn0fpZe9VRpYrgG+HDlISHweWBqegi5gPW9Sb5BkeAfoGjqeLxBrNdRvHpqIXAqxS+IilqzAB4NHJfiewA4pMS/idlG82x2ZmaZcg3azCxTTtBmZplygjYzy5QTtJlZppygzcwy5QRtZpYpJ2gzs0z9Dwlb+MBOfY+SAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 1080x288 with 2 Axes>"]},"metadata":{"needs_background":"light"}}]}]}