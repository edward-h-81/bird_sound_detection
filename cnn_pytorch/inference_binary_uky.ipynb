{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"inference_binary_uky.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyOoc9iJatcJnpxYmasllEaA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"trEzM0OQOxHp","executionInfo":{"status":"ok","timestamp":1629621146737,"user_tz":-60,"elapsed":436,"user":{"displayName":"Edward Hulme","photoUrl":"","userId":"12267249823946796482"}},"outputId":"a4aa212e-2e91-4496-ad60-6294feb37e38"},"source":["# Load the Drive helper and mount\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vo9L40mCO1Rn"},"source":["import sys\n","sys.path.insert(0,'/content/drive/My Drive/MSc_Project_Colab/BAD_PyTorch/')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"62XuvKFYO39I","executionInfo":{"status":"ok","timestamp":1629621152440,"user_tz":-60,"elapsed":2994,"user":{"displayName":"Edward Hulme","photoUrl":"","userId":"12267249823946796482"}},"outputId":"1cbb035b-c0d9-4463-cf0f-17f134903289"},"source":["!pip install torchaudio"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torchaudio in /usr/local/lib/python3.7/dist-packages (0.9.0)\n","Requirement already satisfied: torch==1.9.0 in /usr/local/lib/python3.7/dist-packages (from torchaudio) (1.9.0+cu102)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchaudio) (3.7.4.3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bRIjHOMZ1T6X","executionInfo":{"status":"ok","timestamp":1629621156373,"user_tz":-60,"elapsed":2206,"user":{"displayName":"Edward Hulme","photoUrl":"","userId":"12267249823946796482"}},"outputId":"0a40a250-0300-455a-f897-76b060df3816"},"source":["from torch import nn\n","from torchsummary import summary\n","\n","\n","class CNNNetwork(nn.Module):\n","\n","    def __init__(self):\n","        super().__init__()\n","        self.conv1 = nn.Sequential(\n","            nn.Conv2d(\n","                in_channels=1,\n","                out_channels=16,\n","                kernel_size=3,\n","                stride=1,\n","                padding='valid'\n","            ),\n","            nn.BatchNorm2d(16),\n","            nn.LeakyReLU(0.001),\n","            nn.MaxPool2d(kernel_size=3)\n","        )\n","        self.conv2 = nn.Sequential(\n","            nn.Conv2d(\n","                in_channels=16,\n","                out_channels=16,\n","                kernel_size=3,\n","                stride=1,\n","                padding='valid'\n","            ),\n","            nn.BatchNorm2d(16),\n","            nn.LeakyReLU(0.001),\n","            nn.MaxPool2d(kernel_size=3)\n","        )\n","        self.conv3 = nn.Sequential(\n","            nn.Conv2d(\n","                in_channels=16,\n","                out_channels=16,\n","                kernel_size=3,\n","                stride=1,\n","                padding='valid'\n","            ),\n","            nn.BatchNorm2d(16),\n","            nn.LeakyReLU(0.001),\n","            nn.MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0)\n","        )\n","        self.conv4 = nn.Sequential(\n","            nn.Conv2d(\n","                in_channels=16,\n","                out_channels=16,\n","                kernel_size=3,\n","                stride=1,\n","                padding='valid'\n","            ),\n","            nn.BatchNorm2d(16),\n","            nn.LeakyReLU(0.001),\n","            nn.MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0)\n","        )\n","        self.flatten = nn.Flatten()\n","        self.dropout = nn.Dropout(p=0.5)\n","        self.linearA = nn.Linear(448, 256)\n","        self.batchnormA = nn.BatchNorm1d(256)\n","        self.leakyrelu = nn.LeakyReLU(0.001)\n","        self.linearB = nn.Linear(256, 32)\n","        self.batchnormB = nn.BatchNorm1d(32)\n","\n","        self.linear = nn.Linear(32, 1)\n","        # self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, input_data):\n","        x = self.conv1(input_data)\n","        x = self.conv2(x)\n","        x = self.conv3(x)\n","        x = self.conv4(x)\n","        x = self.flatten(x)\n","        x = self.dropout(x)\n","        x = self.linearA(x)\n","        x = self.batchnormA(x)\n","        x = self.leakyrelu(x)\n","        x = self.dropout(x)\n","        x = self.linearB(x)\n","        x = self.batchnormB(x)\n","        x = self.leakyrelu(x)\n","        x = self.dropout(x)\n","        logits = self.linear(x)\n","\n","        # predictions = self.sigmoid(logits)\n","        return logits\n","\n","\n","if __name__ == \"__main__\":\n","    cnn = CNNNetwork()\n","    summary(cnn.cuda(), (1, 80, 698))\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1          [-1, 16, 78, 696]             160\n","       BatchNorm2d-2          [-1, 16, 78, 696]              32\n","         LeakyReLU-3          [-1, 16, 78, 696]               0\n","         MaxPool2d-4          [-1, 16, 26, 232]               0\n","            Conv2d-5          [-1, 16, 24, 230]           2,320\n","       BatchNorm2d-6          [-1, 16, 24, 230]              32\n","         LeakyReLU-7          [-1, 16, 24, 230]               0\n","         MaxPool2d-8            [-1, 16, 8, 76]               0\n","            Conv2d-9            [-1, 16, 6, 74]           2,320\n","      BatchNorm2d-10            [-1, 16, 6, 74]              32\n","        LeakyReLU-11            [-1, 16, 6, 74]               0\n","        MaxPool2d-12            [-1, 16, 6, 24]               0\n","           Conv2d-13            [-1, 16, 4, 22]           2,320\n","      BatchNorm2d-14            [-1, 16, 4, 22]              32\n","        LeakyReLU-15            [-1, 16, 4, 22]               0\n","        MaxPool2d-16             [-1, 16, 4, 7]               0\n","          Flatten-17                  [-1, 448]               0\n","          Dropout-18                  [-1, 448]               0\n","           Linear-19                  [-1, 256]         114,944\n","      BatchNorm1d-20                  [-1, 256]             512\n","        LeakyReLU-21                  [-1, 256]               0\n","          Dropout-22                  [-1, 256]               0\n","           Linear-23                   [-1, 32]           8,224\n","      BatchNorm1d-24                   [-1, 32]              64\n","        LeakyReLU-25                   [-1, 32]               0\n","          Dropout-26                   [-1, 32]               0\n","           Linear-27                    [-1, 1]              33\n","================================================================\n","Total params: 131,025\n","Trainable params: 131,025\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.21\n","Forward/backward pass size (MB): 22.94\n","Params size (MB): 0.50\n","Estimated Total Size (MB): 23.66\n","----------------------------------------------------------------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":391},"id":"68ssg3TiMArz","executionInfo":{"status":"error","timestamp":1629637360036,"user_tz":-60,"elapsed":1782,"user":{"displayName":"Edward Hulme","photoUrl":"","userId":"12267249823946796482"}},"outputId":"7627f518-a64d-47ad-a10c-dd0802330ec5"},"source":["import torch\n","import torchaudio\n","from torch import nn\n","\n","from random import seed\n","from random import random\n","import matplotlib\n","import matplotlib.pyplot as plt\n","\n","from dcasedatasetcpu import DCASE_Dataset\n","# from cnnbinary_uky import CNNNetwork\n","# from train_binary import ANNOTATIONS_FILE, AUDIO_DIR, SAMPLE_RATE, DURATION, NUM_SAMPLES\n","\n","ANNOTATIONS_birdvox = '/content/drive/My Drive/DCASE_Datasets/labels/BirdVox-DCASE20k.csv'\n","ANNOTATIONS_warblr = '/content/drive/My Drive/DCASE_Datasets/labels/warblrb10k.csv'\n","ANNOTATIONS_freefield = '/content/drive/My Drive/DCASE_Datasets/labels/ff1010bird.csv'\n","AUDIO_DIR = '/content/drive/My Drive/DCASE_Datasets/audio/'\n","SAMPLE_RATE = 22050\n","DURATION = 10\n","NUM_SAMPLES = 22050 * DURATION\n","THRESHOLD = 0.5\n","\n","\n","class_mapping = [\n","    \"no-bird\",\n","    \"bird\"\n","]\n","\n","\n","def predict(model, input, target, class_mapping):\n","    model.eval()\n","    with torch.no_grad():\n","        predictions = model(input).cuda()\n","        sigmoid = nn.Sigmoid()\n","        predictions = sigmoid(predictions)\n","        print(predictions)\n","        # Tensor (1, 10) -> [ [0.1, 0.01, ..., 0.6] ]\n","        if predictions[0] > THRESHOLD:\n","\n","          # predicted_index = predictions[0].argmax(0)\n","          predicted_index = 1\n","        elif predictions[0] < THRESHOLD:\n","          predicted_index = 0\n","        print(predicted_index)\n","        predicted = class_mapping[predicted_index]\n","        expected = class_mapping[target]\n","    return predicted, expected\n","\n","\n","if __name__ == \"__main__\":\n","    # load back the model\n","    cnn = CNNNetwork()\n","    state_dict = torch.load(\"/content/drive/My Drive/MSc_Project_Colab/BAD_PyTorch/cnn_birdvox20k_V2.pth\", map_location=torch.device('cpu'))\n","    cnn.load_state_dict(state_dict)\n","\n","    # load DCASE dataset\n","    mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n","        sample_rate=SAMPLE_RATE,\n","        n_fft=1024,\n","        hop_length=316,\n","        n_mels=80,\n","        power=1\n","    )\n","\n","    t1masking = torchaudio.transforms.TimeMasking(time_mask_param=40)\n","    t2masking = torchaudio.transforms.TimeMasking(time_mask_param=40)\n","    fmasking = torchaudio.transforms.FrequencyMasking(freq_mask_param=10)\n","\n","    dcase = DCASE_Dataset(ANNOTATIONS_freefield,\n","                            AUDIO_DIR,\n","                            mel_spectrogram,\n","                            SAMPLE_RATE,\n","                            NUM_SAMPLES,\n","                            \"cpu\")\n","\n","\n","    # get a sample from the dcase dataset for inference\n","\n","    count = 0\n","    index = 0\n","    correct = 0\n","    num_files = 1000\n","    countnobird = 0\n","    countbird = 0\n","    while count < num_files:\n","\n","      value = random()\n","      val_label = random()\n","\n","      input, target = dcase[index][0], dcase[index][1]\n","\n","\n","      if target == 0:\n","        if val_label < 0.667:\n","          index += 1\n","          continue\n","\n","      # if value > 0.5:\n","      #   input = t1masking(input)\n","      #   input = t2masking(input)\n","      #   input = fmasking(input)\n","      #   input = input\n","\n","      # def plot_spectrogram(spec, title=None, ylabel='freq_bin', aspect='auto', xmax=None):\n","      #     fig, axs = plt.subplots(1, 1)\n","      #     axs.set_title(title or 'Spectrogram')\n","      #     axs.set_ylabel(ylabel)\n","      #     axs.set_xlabel('frame')\n","      #     spec = spec.cpu()\n","      #     spec = spec[0,:,:]\n","      #     im = axs.imshow(spec, origin='lower', aspect=aspect)\n","      #     if xmax:\n","      #       axs.set_xlim((0, xmax))\n","      #     fig.colorbar(im, ax=axs)\n","      #     plt.show(block=False)\n","\n","      \n","      # plot_spectrogram(input)\n","\n","\n","      input.unsqueeze_(0)\n","\n","      index += 1\n","      count += 1\n","\n","      if target == 1:\n","        countbird += 1\n","      else:\n","        countnobird += 1\n","\n","    # make an inference\n","      predicted, expected = predict(cnn, input, target,\n","                                  class_mapping)\n","      if predicted == expected:\n","        correct += 1\n","      print(f\"Predicted: '{predicted}', expected: '{expected}'\")\n","      print()\n","\n","    accuracy = correct / num_files\n","    print(accuracy)\n","    print(\"bird: {}\".format(countbird))\n","    print(\"no-bird: {}\".format(countnobird))"],"execution_count":45,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-45-8f4da88b1bb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mcnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNNNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/My Drive/MSc_Project_Colab/BAD_PyTorch/cnn_birdvox20k_V1.pth\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m# load DCASE dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m-> 1407\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m   1408\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for CNNNetwork:\n\tsize mismatch for linearA.weight: copying a param with shape torch.Size([256, 752]) from checkpoint, the shape in current model is torch.Size([256, 448])."]}]}]}